# Singapore SMB Customer Enquiry Support AI Agent
# Master Execution Plan

**Author:** Matrix Agent  
**Version:** 2.0  
**Date:** 2026-01-03  
**Status:** Ready for Implementation

---

## Table of Contents

1. [Executive Summary](#1-executive-summary)
2. [Architecture Validation & Updates](#2-architecture-validation--updates)
3. [Re-Imagined System Architecture](#3-re-imagined-system-architecture)
4. [Technology Stack (Validated 2025)](#4-technology-stack-validated-2025)
5. [Complete File Hierarchy](#5-complete-file-hierarchy)
6. [Key Files & Descriptions](#6-key-files--descriptions)
7. [Master Execution Phases](#7-master-execution-phases)
8. [Phase 1: Foundation & Infrastructure](#phase-1-foundation--infrastructure)
9. [Phase 2: Core Backend Development](#phase-2-core-backend-development)
10. [Phase 3: RAG Pipeline Implementation](#phase-3-rag-pipeline-implementation)
11. [Phase 4: Agent Orchestration (LangGraph)](#phase-4-agent-orchestration-langgraph)
12. [Phase 5: Frontend Chat Widget](#phase-5-frontend-chat-widget)
13. [Phase 6: Integration & Testing](#phase-6-integration--testing)
14. [Phase 7: Deployment & Monitoring](#phase-7-deployment--monitoring)
15. [Success Metrics & Validation](#8-success-metrics--validation)

---

## 1. Executive Summary

This Master Execution Plan presents a **thoroughly researched and validated** architecture for building a Singapore SMB Customer Enquiry Support AI Agent. The design incorporates **2025 best practices** from:

- **LangGraph/LangChain 1.0** patterns for stateful agent orchestration
- **RAG optimization** with hybrid search (BM25 + vectors + RRF fusion)
- **FastAPI production patterns** for scalable AI backends
- **React 18+** chat widget patterns with SSE streaming
- **Pydantic 2.0** for robust data validation

### Key Architecture Decisions (Validated by Research)

| Component | Original Design | Research Validation | Final Decision |
|-----------|----------------|---------------------|----------------|
| Streaming | WebSocket | SSE preferred for LLM (simpler, auto-reconnect) | **SSE primary, WebSocket secondary** |
| State Management | Custom | LangGraph checkpointers are production-ready | **LangGraph with PostgreSQL checkpointer** |
| Vector DB | Qdrant | Qdrant validated (326 QPS, SOC2, hybrid search) | **Qdrant Cloud** |
| Reranking | Cross-encoder | Cohere Rerank-4 achieves perfect RAGAS scores | **Cohere Rerank-4-Multilingual** |
| Frontend State | Context API | Zustand is 2025 recommendation | **Zustand + TanStack Query** |
| RAG Framework | LangChain | LlamaIndex 40% faster retrieval | **Hybrid: LlamaIndex for RAG + LangGraph for agents** |

---

## 2. Architecture Validation & Updates

### 2.1 Original Architecture Review

The original design was **fundamentally sound** with correct choices for:
- âœ… LangGraph for agent orchestration
- âœ… 3-tier hierarchical memory architecture
- âœ… Hybrid search with RRF fusion
- âœ… Cross-encoder reranking
- âœ… Singapore SMB context awareness

### 2.2 Research-Driven Updates

Based on comprehensive research, the following **enhancements** are incorporated:

#### A. Streaming Architecture Update
```
ORIGINAL: WebSocket-only streaming
UPDATED:  SSE primary (simpler infrastructure, auto-reconnect)
          + WebSocket for bidirectional features (typing indicators)
```

#### B. RAG Pipeline Enhancement
```
ORIGINAL: LangChain RAG
UPDATED:  LlamaIndex for retrieval (40% faster, 35% higher accuracy)
          + LangGraph for agent orchestration (best of both worlds)
```

#### C. Document Ingestion
```
ORIGINAL: Unstructured.io
UPDATED:  LlamaParse (RAG-native, citation support, variable chunking)
          + Docling fallback (complex PDFs with tables)
```

#### D. Chunking Strategy
```
ORIGINAL: Fixed 400 tokens
UPDATED:  Recursive (400 tokens) default
          + Semantic chunking for high-failure sections
          + Page-level for PDF-heavy content
```

#### E. Frontend State Management
```
ORIGINAL: React Context
UPDATED:  Zustand for client state (minimal boilerplate)
          + TanStack Query for server state (caching, streaming)
          + Vercel AI SDK useChat hook for chat state
```

#### F. Embedding Model
```
ORIGINAL: OpenAI text-embedding-3-small
UPDATED:  Cohere Embed-4 (multilingual, SEA languages, $0.12/M tokens)
```

---

## 3. Re-Imagined System Architecture

### 3.1 High-Level Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              CLIENT LAYER                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Embeddable Chat   â”‚    â”‚    Admin Dashboard   â”‚    â”‚   Mobile App    â”‚ â”‚
â”‚  â”‚      Widget         â”‚    â”‚    (Future Phase)    â”‚    â”‚  (Future Phase) â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”‚  â”‚ Shadow DOM    â”‚  â”‚                                                    â”‚
â”‚  â”‚  â”‚ + React 18    â”‚  â”‚    Technology:                                     â”‚
â”‚  â”‚  â”‚ + Zustand     â”‚  â”‚    - TypeScript + Vite                            â”‚
â”‚  â”‚  â”‚ + TanStack Q  â”‚  â”‚    - Shadcn/UI + Tailwind                         â”‚
â”‚  â”‚  â”‚ + Framer      â”‚  â”‚    - react-window (virtualization)                â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    - react-markdown + remark-gfm                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                              SSE (primary) / WebSocket (secondary)
                                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              API GATEWAY                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    FastAPI Application                               â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
â”‚  â”‚  â”‚   /auth     â”‚  â”‚   /chat     â”‚  â”‚  /webhooks  â”‚  â”‚  /health   â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  (JWT+OAuth)â”‚  â”‚  (REST+SSE) â”‚  â”‚  (Callbacks)â”‚  â”‚  (Probes)  â”‚ â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Middleware: CORS | Rate Limiting (SlowAPI) | Request Logging        â”‚   â”‚
â”‚  â”‚  Observability: OpenTelemetry | Prometheus | structlog               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           AGENT ORCHESTRATION LAYER                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    LangGraph State Machine                           â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚   â”‚
â”‚  â”‚   â”‚  INPUT   â”‚â”€â”€â”€â–¶â”‚   ROUTER     â”‚â”€â”€â”€â–¶â”‚   RETRIEVER  â”‚              â”‚   â”‚
â”‚  â”‚   â”‚  NODE    â”‚    â”‚    NODE      â”‚    â”‚     NODE     â”‚              â”‚   â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚   â”‚
â”‚  â”‚        â”‚                 â”‚                    â”‚                       â”‚   â”‚
â”‚  â”‚        â”‚                 â–¼                    â–¼                       â”‚   â”‚
â”‚  â”‚        â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚   â”‚
â”‚  â”‚        â”‚          â”‚   GRADER     â”‚    â”‚   RERANKER   â”‚              â”‚   â”‚
â”‚  â”‚        â”‚          â”‚    NODE      â”‚    â”‚     NODE     â”‚              â”‚   â”‚
â”‚  â”‚        â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚   â”‚
â”‚  â”‚        â”‚                 â”‚                    â”‚                       â”‚   â”‚
â”‚  â”‚        â–¼                 â–¼                    â–¼                       â”‚   â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚   â”‚
â”‚  â”‚   â”‚              GENERATOR NODE (LLM)                 â”‚              â”‚   â”‚
â”‚  â”‚   â”‚         + Streaming Token Output                  â”‚              â”‚   â”‚
â”‚  â”‚   â”‚         + Singapore Context Awareness             â”‚              â”‚   â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚   â”‚
â”‚  â”‚        â”‚                                                              â”‚   â”‚
â”‚  â”‚        â–¼                                                              â”‚   â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚   â”‚
â”‚  â”‚   â”‚  OUTPUT  â”‚â”€â”€â”€â–¶â”‚  CHECKPOINT  â”‚  (PostgreSQL Checkpointer)       â”‚   â”‚
â”‚  â”‚   â”‚   NODE   â”‚    â”‚    SAVE      â”‚                                  â”‚   â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Tools: [search_knowledge_base, escalate_to_human, get_order_status] â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              RAG PIPELINE                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    LlamaIndex RAG Engine                             â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚   Query Transformers          Retrieval               Post-Processing â”‚   â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚   â”‚ â€¢ HyDE          â”‚   â”‚ â€¢ BM25 (sparse)  â”‚   â”‚ â€¢ RRF Fusion    â”‚  â”‚   â”‚
â”‚  â”‚   â”‚ â€¢ Multi-Query   â”‚   â”‚ â€¢ Cohere Embed   â”‚   â”‚ â€¢ Cohere Rerank â”‚  â”‚   â”‚
â”‚  â”‚   â”‚ â€¢ Step-Back     â”‚   â”‚ â€¢ Metadata Filterâ”‚   â”‚ â€¢ Context Comp  â”‚  â”‚   â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              DATA LAYER                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚   PostgreSQL    â”‚   â”‚   Qdrant Cloud  â”‚   â”‚      Redis Cluster       â”‚  â”‚
â”‚   â”‚                 â”‚   â”‚                 â”‚   â”‚                          â”‚  â”‚
â”‚   â”‚ â€¢ Users         â”‚   â”‚ â€¢ Document      â”‚   â”‚ â€¢ Session cache          â”‚  â”‚
â”‚   â”‚ â€¢ Conversations â”‚   â”‚   embeddings    â”‚   â”‚ â€¢ Rate limiting          â”‚  â”‚
â”‚   â”‚ â€¢ Messages      â”‚   â”‚ â€¢ Hybrid search â”‚   â”‚ â€¢ Short-term memory      â”‚  â”‚
â”‚   â”‚ â€¢ Checkpoints   â”‚   â”‚ â€¢ Metadata      â”‚   â”‚ â€¢ Connection state       â”‚  â”‚
â”‚   â”‚ â€¢ Audit logs    â”‚   â”‚   filtering     â”‚   â”‚                          â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 Data Flow Sequence

```
User Message
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. SSE Connection receives message                               â”‚
â”‚ 2. Rate limiting check (SlowAPI + Redis)                        â”‚
â”‚ 3. JWT validation + session retrieval                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. LangGraph processes through state machine:                    â”‚
â”‚    a. Input validation + language detection                     â”‚
â”‚    b. Router decides: FAQ / Complex / Escalation                â”‚
â”‚    c. Retriever fetches from Qdrant (hybrid search)             â”‚
â”‚    d. Reranker scores with Cohere Rerank-4                      â”‚
â”‚    e. Generator produces response with streaming                 â”‚
â”‚    f. Checkpoint saved to PostgreSQL                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Response streamed via SSE (token by token)                    â”‚
â”‚ 6. Message persisted to PostgreSQL                              â”‚
â”‚ 7. Analytics logged (background task)                           â”‚
â”‚ 8. Memory updated (Redis short-term + PostgreSQL long-term)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4. Technology Stack (Validated 2025)

### 4.1 Backend Stack

| Category | Technology | Version | Justification |
|----------|-----------|---------|---------------|
| **Framework** | FastAPI | 0.110+ | Async-first, automatic docs, production-proven |
| **Agent Orchestration** | LangGraph | 0.2+ | Stateful workflows, checkpointing, streaming |
| **RAG Engine** | LlamaIndex | 0.11+ | 40% faster retrieval, 160+ data formats |
| **LLM Provider** | OpenAI GPT-4 | gpt-4-turbo | Best quality for customer support |
| **Embeddings** | Cohere Embed-4 | embed-4 | Multilingual (SEA), $0.12/M tokens |
| **Reranking** | Cohere Rerank | rerank-4-multilingual | Perfect RAGAS scores, 100+ languages |
| **Vector DB** | Qdrant | 1.8+ | Hybrid search, SOC2, 326 QPS |
| **Primary DB** | PostgreSQL | 16+ | ACID, checkpoints, audit logs |
| **Cache/Session** | Redis | 7+ | Session cache, rate limiting, pub/sub |
| **Task Queue** | ARQ | 0.26+ | Async task queue (lighter than Celery) |

### 4.2 Frontend Stack

| Category | Technology | Version | Justification |
|----------|-----------|---------|---------------|
| **Framework** | React | 18.3+ | Concurrent features, SSR support |
| **Build Tool** | Vite | 5+ | Fast HMR, optimized builds |
| **Language** | TypeScript | 5.4+ | Type safety, better DX |
| **Styling** | Tailwind CSS | 3.4+ | Utility-first, consistent design |
| **Components** | Shadcn/UI | Latest | Accessible, customizable |
| **State (Client)** | Zustand | 4+ | Minimal boilerplate, React 18 compatible |
| **State (Server)** | TanStack Query | 5+ | Caching, streaming support |
| **Chat Hook** | Vercel AI SDK | 4+ | useChat, SSE streaming built-in |
| **Virtualization** | react-window | 1.8+ | Dynamic height, performant lists |
| **Markdown** | react-markdown | 9+ | Safe rendering, remark plugins |
| **Animation** | Framer Motion | 11+ | Smooth message animations |

### 4.3 Infrastructure & DevOps

| Category | Technology | Justification |
|----------|-----------|---------------|
| **Containerization** | Docker + Docker Compose | Standard, reproducible |
| **Observability** | OpenTelemetry + Prometheus + Grafana | Full-stack tracing |
| **Logging** | structlog | Structured JSON logs |
| **Rate Limiting** | SlowAPI + Redis | Distributed rate limiting |
| **Document Parsing** | LlamaParse + Docling | RAG-native + complex PDFs |
| **Evaluation** | RAGAs | Faithfulness, context recall metrics |

---

## 5. Complete File Hierarchy

```
singapore-smb-support-agent/
â”‚
â”œâ”€â”€ ğŸ“ backend/                           # FastAPI Backend Application
â”‚   â”œâ”€â”€ ğŸ“ alembic/                       # Database Migrations
â”‚   â”‚   â”œâ”€â”€ versions/                     # Migration version files
â”‚   â”‚   â”œâ”€â”€ env.py                        # Alembic environment config
â”‚   â”‚   â””â”€â”€ script.py.mako                # Migration template
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ src/                           # Source Code (Domain-Driven)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“ core/                      # Core Infrastructure
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py                 # Pydantic Settings (env vars)
â”‚   â”‚   â”‚   â”œâ”€â”€ database.py               # SQLAlchemy async engine + session
â”‚   â”‚   â”‚   â”œâ”€â”€ redis.py                  # Async Redis client
â”‚   â”‚   â”‚   â”œâ”€â”€ security.py               # JWT utilities, password hashing
â”‚   â”‚   â”‚   â”œâ”€â”€ middleware.py             # CORS, logging, timing middleware
â”‚   â”‚   â”‚   â”œâ”€â”€ logging.py                # structlog configuration
â”‚   â”‚   â”‚   â”œâ”€â”€ limiter.py                # SlowAPI rate limiter setup
â”‚   â”‚   â”‚   â”œâ”€â”€ telemetry.py              # OpenTelemetry setup
â”‚   â”‚   â”‚   â”œâ”€â”€ exceptions.py             # Global exception handlers
â”‚   â”‚   â”‚   â””â”€â”€ health.py                 # Health check endpoints
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“ auth/                      # Authentication Domain
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ router.py                 # Auth endpoints (/token, /refresh)
â”‚   â”‚   â”‚   â”œâ”€â”€ schemas.py                # TokenRequest, TokenResponse
â”‚   â”‚   â”‚   â”œâ”€â”€ models.py                 # User, RefreshToken models
â”‚   â”‚   â”‚   â”œâ”€â”€ service.py                # Auth business logic
â”‚   â”‚   â”‚   â”œâ”€â”€ dependencies.py           # get_current_user, get_active_user
â”‚   â”‚   â”‚   â”œâ”€â”€ constants.py              # Token types, expiry times
â”‚   â”‚   â”‚   â””â”€â”€ exceptions.py             # InvalidCredentials, TokenExpired
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“ chat/                      # Chat Domain
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ router.py                 # Chat endpoints (REST + SSE)
â”‚   â”‚   â”‚   â”œâ”€â”€ schemas.py                # Message, Conversation schemas
â”‚   â”‚   â”‚   â”œâ”€â”€ models.py                 # Conversation, Message DB models
â”‚   â”‚   â”‚   â”œâ”€â”€ service.py                # Chat business logic
â”‚   â”‚   â”‚   â”œâ”€â”€ repository.py             # Database queries (repository pattern)
â”‚   â”‚   â”‚   â”œâ”€â”€ dependencies.py           # valid_conversation, rate limits
â”‚   â”‚   â”‚   â”œâ”€â”€ streaming.py              # SSE streaming utilities
â”‚   â”‚   â”‚   â”œâ”€â”€ websocket_manager.py      # WebSocket connection manager
â”‚   â”‚   â”‚   â”œâ”€â”€ session_manager.py        # Redis session management
â”‚   â”‚   â”‚   â””â”€â”€ exceptions.py             # ConversationNotFound, etc.
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“ agents/                    # LangGraph Agent Domain
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ graph.py                  # Main LangGraph StateGraph definition
â”‚   â”‚   â”‚   â”œâ”€â”€ state.py                  # AgentState TypedDict
â”‚   â”‚   â”‚   â”œâ”€â”€ nodes/                    # Individual graph nodes
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ input_node.py         # Input processing + language detection
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ router_node.py        # Query classification + routing
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ retriever_node.py     # RAG retrieval node
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ grader_node.py        # Document relevance grading
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ reranker_node.py      # Cross-encoder reranking
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ generator_node.py     # LLM response generation
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ output_node.py        # Response formatting + streaming
â”‚   â”‚   â”‚   â”œâ”€â”€ tools/                    # Agent tools
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ knowledge_search.py   # Search knowledge base tool
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ escalation.py         # Escalate to human tool
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ order_status.py       # Get order status tool (example)
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ appointment.py        # Book appointment tool (example)
â”‚   â”‚   â”‚   â”œâ”€â”€ prompts/                  # System prompts
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py           # Prompt loader
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ system.md             # Main system prompt
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ router.md             # Router classification prompt
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ grader.md             # Document grading prompt
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ generator.md          # Response generation prompt
â”‚   â”‚   â”‚   â”œâ”€â”€ memory.py                 # Conversation memory management
â”‚   â”‚   â”‚   â”œâ”€â”€ checkpointer.py           # PostgreSQL checkpointer setup
â”‚   â”‚   â”‚   â””â”€â”€ callbacks.py              # LangChain callbacks for streaming
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“ rag/                       # RAG Pipeline Domain
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ pipeline.py               # Main RAG pipeline orchestration
â”‚   â”‚   â”‚   â”œâ”€â”€ ingestion/                # Document ingestion
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ loader.py             # LlamaParse document loader
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ chunker.py            # Chunking strategies
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ embedder.py           # Cohere embedding generation
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ uploader.py           # Qdrant vector upload
â”‚   â”‚   â”‚   â”œâ”€â”€ retrieval/                # Retrieval components
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ hybrid_retriever.py   # BM25 + dense hybrid retriever
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ query_transformer.py  # HyDE, multi-query, step-back
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ reranker.py           # Cohere reranker integration
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ metadata_filter.py    # Metadata filtering utilities
â”‚   â”‚   â”‚   â”œâ”€â”€ index.py                  # LlamaIndex setup
â”‚   â”‚   â”‚   â””â”€â”€ evaluation.py             # RAGAs evaluation utilities
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“ knowledge/                 # Knowledge Base Domain
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ router.py                 # Knowledge management endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ schemas.py                # Document, Collection schemas
â”‚   â”‚   â”‚   â”œâ”€â”€ models.py                 # Document, Collection DB models
â”‚   â”‚   â”‚   â”œâ”€â”€ service.py                # Knowledge base operations
â”‚   â”‚   â”‚   â””â”€â”€ repository.py             # Document metadata queries
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“ analytics/                 # Analytics Domain (Future)
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ router.py                 # Analytics endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ schemas.py                # Analytics schemas
â”‚   â”‚   â”‚   â”œâ”€â”€ service.py                # Analytics aggregation
â”‚   â”‚   â”‚   â””â”€â”€ metrics.py                # Custom metrics definitions
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“ common/                    # Shared Utilities
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ models.py                 # Base model classes
â”‚   â”‚   â”‚   â”œâ”€â”€ schemas.py                # Common response schemas
â”‚   â”‚   â”‚   â”œâ”€â”€ pagination.py             # Pagination utilities
â”‚   â”‚   â”‚   â”œâ”€â”€ utils.py                  # General utilities
â”‚   â”‚   â”‚   â””â”€â”€ singapore.py              # Singapore-specific utilities
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ main.py                       # Application entry point
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ tests/                         # Test Suite
â”‚   â”‚   â”œâ”€â”€ conftest.py                   # Pytest fixtures
â”‚   â”‚   â”œâ”€â”€ ğŸ“ unit/                      # Unit tests
â”‚   â”‚   â”‚   â”œâ”€â”€ test_auth.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_chat.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_agents.py
â”‚   â”‚   â”‚   â””â”€â”€ test_rag.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“ integration/               # Integration tests
â”‚   â”‚   â”‚   â”œâ”€â”€ test_api_chat.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_rag_pipeline.py
â”‚   â”‚   â”‚   â””â”€â”€ test_agent_graph.py
â”‚   â”‚   â””â”€â”€ ğŸ“ e2e/                       # End-to-end tests
â”‚   â”‚       â””â”€â”€ test_full_conversation.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ scripts/                       # Utility Scripts
â”‚   â”‚   â”œâ”€â”€ seed_database.py              # Database seeding
â”‚   â”‚   â”œâ”€â”€ ingest_documents.py           # Document ingestion CLI
â”‚   â”‚   â”œâ”€â”€ evaluate_rag.py               # RAGAs evaluation runner
â”‚   â”‚   â””â”€â”€ migrate_memory.py             # Memory tier migration
â”‚   â”‚
â”‚   â”œâ”€â”€ alembic.ini                       # Alembic configuration
â”‚   â”œâ”€â”€ pyproject.toml                    # Python dependencies (uv/poetry)
â”‚   â”œâ”€â”€ Dockerfile                        # Backend Docker image
â”‚   â””â”€â”€ .env.example                      # Environment template
â”‚
â”œâ”€â”€ ğŸ“ frontend/                          # React Frontend (Embeddable Widget)
â”‚   â”œâ”€â”€ ğŸ“ src/
â”‚   â”‚   â”œâ”€â”€ ğŸ“ components/                # React Components
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ chat/                  # Chat-specific components
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ChatWidget.tsx        # Main widget container
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ChatHeader.tsx        # Widget header (title, close)
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ MessageList.tsx       # Virtualized message list
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ MessageBubble.tsx     # Individual message rendering
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ InputArea.tsx         # Text input + send button
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ TypingIndicator.tsx   # AI typing animation
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ QuickReplies.tsx      # Suggested quick replies
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ChatTrigger.tsx       # Floating trigger button
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ ui/                    # Shadcn UI components
â”‚   â”‚   â”‚       â”œâ”€â”€ button.tsx
â”‚   â”‚   â”‚       â”œâ”€â”€ input.tsx
â”‚   â”‚   â”‚       â”œâ”€â”€ scroll-area.tsx
â”‚   â”‚   â”‚       â””â”€â”€ ...
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“ hooks/                     # Custom React Hooks
â”‚   â”‚   â”‚   â”œâ”€â”€ useChat.ts                # Vercel AI SDK wrapper
â”‚   â”‚   â”‚   â”œâ”€â”€ useStreamingText.ts       # Token-by-token animation
â”‚   â”‚   â”‚   â”œâ”€â”€ useAutoScroll.ts          # Auto-scroll to bottom
â”‚   â”‚   â”‚   â”œâ”€â”€ useVirtualizedList.ts     # react-window integration
â”‚   â”‚   â”‚   â””â”€â”€ useWidgetConfig.ts        # Widget configuration
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“ stores/                    # Zustand State Stores
â”‚   â”‚   â”‚   â”œâ”€â”€ chatStore.ts              # Chat state (messages, typing)
â”‚   â”‚   â”‚   â”œâ”€â”€ uiStore.ts                # UI state (open/closed, theme)
â”‚   â”‚   â”‚   â””â”€â”€ sessionStore.ts           # Session management
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“ lib/                       # Utilities & Config
â”‚   â”‚   â”‚   â”œâ”€â”€ api.ts                    # API client (TanStack Query)
â”‚   â”‚   â”‚   â”œâ”€â”€ sse.ts                    # SSE connection utilities
â”‚   â”‚   â”‚   â”œâ”€â”€ markdown.ts               # Markdown renderer config
â”‚   â”‚   â”‚   â”œâ”€â”€ utils.ts                  # General utilities
â”‚   â”‚   â”‚   â””â”€â”€ constants.ts              # Constants & config
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“ styles/                    # Styling
â”‚   â”‚   â”‚   â”œâ”€â”€ globals.css               # Tailwind base styles
â”‚   â”‚   â”‚   â””â”€â”€ widget.css                # Widget-specific styles
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“ types/                     # TypeScript Types
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.ts                   # Chat-related types
â”‚   â”‚   â”‚   â”œâ”€â”€ api.ts                    # API response types
â”‚   â”‚   â”‚   â””â”€â”€ config.ts                 # Widget config types
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ App.tsx                       # Main App component
â”‚   â”‚   â”œâ”€â”€ main.tsx                      # Application entry (standard)
â”‚   â”‚   â””â”€â”€ widget.tsx                    # Widget entry (embeddable)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ public/
â”‚   â”‚   â””â”€â”€ widget-loader.js              # Script tag loader
â”‚   â”‚
â”‚   â”œâ”€â”€ index.html                        # Development HTML
â”‚   â”œâ”€â”€ package.json                      # npm dependencies
â”‚   â”œâ”€â”€ vite.config.ts                    # Vite configuration
â”‚   â”œâ”€â”€ tailwind.config.ts                # Tailwind configuration
â”‚   â”œâ”€â”€ tsconfig.json                     # TypeScript configuration
â”‚   â””â”€â”€ .env.example                      # Environment template
â”‚
â”œâ”€â”€ ğŸ“ infra/                             # Infrastructure Configuration
â”‚   â”œâ”€â”€ ğŸ“ docker/
â”‚   â”‚   â”œâ”€â”€ docker-compose.yml            # Full stack compose
â”‚   â”‚   â”œâ”€â”€ docker-compose.dev.yml        # Development overrides
â”‚   â”‚   â””â”€â”€ docker-compose.prod.yml       # Production overrides
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ kubernetes/                    # K8s manifests (future)
â”‚   â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â”‚   â”œâ”€â”€ service.yaml
â”‚   â”‚   â””â”€â”€ ingress.yaml
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ monitoring/
â”‚   â”‚   â”œâ”€â”€ prometheus/
â”‚   â”‚   â”‚   â””â”€â”€ prometheus.yml            # Prometheus config
â”‚   â”‚   â””â”€â”€ grafana/
â”‚   â”‚       â””â”€â”€ dashboards/
â”‚   â”‚           â”œâ”€â”€ api-dashboard.json    # API metrics dashboard
â”‚   â”‚           â””â”€â”€ llm-dashboard.json    # LLM metrics dashboard
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ scripts/
â”‚       â”œâ”€â”€ setup.sh                      # Initial setup script
â”‚       â”œâ”€â”€ deploy.sh                     # Deployment script
â”‚       â””â”€â”€ backup.sh                     # Database backup script
â”‚
â”œâ”€â”€ ğŸ“ docs/                              # Documentation
â”‚   â”œâ”€â”€ architecture.md                   # Architecture overview
â”‚   â”œâ”€â”€ api-reference.md                  # API documentation
â”‚   â”œâ”€â”€ deployment-guide.md               # Deployment instructions
â”‚   â”œâ”€â”€ configuration.md                  # Configuration guide
â”‚   â””â”€â”€ troubleshooting.md                # Common issues & solutions
â”‚
â”œâ”€â”€ ğŸ“ knowledge_base/                    # Sample Knowledge Base Content
â”‚   â”œâ”€â”€ faqs/
â”‚   â”‚   â”œâ”€â”€ general.md
â”‚   â”‚   â”œâ”€â”€ billing.md
â”‚   â”‚   â””â”€â”€ technical.md
â”‚   â”œâ”€â”€ policies/
â”‚   â”‚   â”œâ”€â”€ privacy.md
â”‚   â”‚   â””â”€â”€ terms.md
â”‚   â””â”€â”€ products/
â”‚       â””â”€â”€ catalog.md
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .env.example                          # Root environment template
â”œâ”€â”€ README.md                             # Project README
â”œâ”€â”€ Makefile                              # Common commands
â””â”€â”€ MASTER_EXECUTION_PLAN.md              # This document
```

---

## 6. Key Files & Descriptions

### 6.1 Backend Core Files

| File | Purpose | Key Responsibilities |
|------|---------|---------------------|
| `src/main.py` | Application entry point | FastAPI app creation, lifespan management, router mounting, middleware setup |
| `src/core/config.py` | Configuration management | Pydantic BaseSettings, environment variable loading, secrets management |
| `src/core/database.py` | Database connection | Async SQLAlchemy engine, session factory, `get_db` dependency |
| `src/core/redis.py` | Redis client | Async Redis connection, singleton pattern, cache utilities |
| `src/core/telemetry.py` | Observability | OpenTelemetry tracing, Prometheus metrics, LLM-specific metrics |

### 6.2 Agent & RAG Files

| File | Purpose | Key Responsibilities |
|------|---------|---------------------|
| `src/agents/graph.py` | LangGraph definition | StateGraph construction, node connections, conditional edges |
| `src/agents/state.py` | Agent state | TypedDict state schema with messages, context, metadata |
| `src/agents/nodes/generator_node.py` | LLM response | Streaming generation, Singapore context, response formatting |
| `src/agents/checkpointer.py` | State persistence | PostgreSQL checkpointer for conversation continuity |
| `src/rag/pipeline.py` | RAG orchestration | Query â†’ Transform â†’ Retrieve â†’ Rerank â†’ Return |
| `src/rag/retrieval/hybrid_retriever.py` | Hybrid search | BM25 + dense vector + RRF fusion implementation |
| `src/rag/retrieval/reranker.py` | Cross-encoder | Cohere Rerank-4 integration for relevance scoring |

### 6.3 Chat Domain Files

| File | Purpose | Key Responsibilities |
|------|---------|---------------------|
| `src/chat/router.py` | Chat endpoints | REST endpoints + SSE streaming endpoint |
| `src/chat/streaming.py` | SSE utilities | Token streaming, event formatting, connection management |
| `src/chat/session_manager.py` | Session cache | Redis-based session storage, TTL management |
| `src/chat/repository.py` | Data access | Async queries for conversations/messages |

### 6.4 Frontend Key Files

| File | Purpose | Key Responsibilities |
|------|---------|---------------------|
| `src/components/chat/ChatWidget.tsx` | Main widget | Shadow DOM container, state orchestration |
| `src/components/chat/MessageList.tsx` | Message display | react-window virtualization, ARIA live region |
| `src/hooks/useChat.ts` | Chat hook | Vercel AI SDK integration, SSE streaming |
| `src/stores/chatStore.ts` | Chat state | Zustand store for messages, typing state |
| `src/widget.tsx` | Widget entry | Script injection, Shadow DOM setup, config parsing |

---

## 7. Master Execution Phases

### Phase Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         MASTER EXECUTION TIMELINE                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  Phase 1: Foundation        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  (Days 1-3)  â”‚
â”‚  Phase 2: Core Backend      â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  (Days 4-8)  â”‚
â”‚  Phase 3: RAG Pipeline      â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘  (Days 9-12) â”‚
â”‚  Phase 4: Agent Orchestra   â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘  (Days 13-16)â”‚
â”‚  Phase 5: Frontend Widget   â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆ  (Days 17-21)â”‚
â”‚  Phase 6: Integration       â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆ  (Days 22-24)â”‚
â”‚  Phase 7: Deployment        â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆ  (Days 25-28)â”‚
â”‚                                                                              â”‚
â”‚  TOTAL ESTIMATED: 28 Days (4 Weeks)                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Phase Dependencies

```
Phase 1 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚                                                          â”‚
   â–¼                                                          â”‚
Phase 2 â”€â”€â”€â”€â”€â”€â”€â”                                              â”‚
   â”‚           â”‚                                              â”‚
   â–¼           â–¼                                              â”‚
Phase 3 â”€â”€â”€â–º Phase 4 â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚           â”‚
   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
         â–¼
      Phase 5
         â”‚
         â–¼
      Phase 6
         â”‚
         â–¼
      Phase 7
```

---

## Phase 1: Foundation & Infrastructure

### Objectives
- Set up project structure and development environment
- Configure infrastructure services (PostgreSQL, Redis, Qdrant)
- Establish CI/CD foundations
- Create base configurations

### Duration: 3 Days

### Detailed TODO Checklist

#### Day 1: Project Initialization

- [ ] **1.1 Repository Setup**
  - [ ] Initialize Git repository
  - [ ] Create `.gitignore` with Python, Node, IDE patterns
  - [ ] Set up branch protection rules
  - [ ] Configure commit hooks (pre-commit)

- [ ] **1.2 Backend Project Structure**
  - [ ] Create `backend/` directory structure (as per file hierarchy)
  - [ ] Initialize `pyproject.toml` with uv/poetry
  - [ ] Install core dependencies:
    - [ ] `fastapi[all]`, `uvicorn[standard]`
    - [ ] `sqlalchemy[asyncio]`, `asyncpg`, `alembic`
    - [ ] `redis`, `pydantic-settings`
    - [ ] `python-jose[cryptography]`, `passlib[bcrypt]`
    - [ ] `structlog`, `opentelemetry-*`
  - [ ] Create `src/__init__.py` files for all packages

- [ ] **1.3 Frontend Project Structure**
  - [ ] Initialize Vite + React + TypeScript project
  - [ ] Install dependencies:
    - [ ] `@tanstack/react-query`, `zustand`
    - [ ] `ai` (Vercel AI SDK)
    - [ ] `react-window`, `react-markdown`, `remark-gfm`
    - [ ] `framer-motion`
  - [ ] Configure Tailwind CSS + Shadcn/UI
  - [ ] Set up path aliases in `tsconfig.json`

#### Day 2: Infrastructure Configuration

- [ ] **1.4 Docker Configuration**
  - [ ] Create `backend/Dockerfile` (multi-stage build)
  - [ ] Create `frontend/Dockerfile` (build + nginx)
  - [ ] Create `infra/docker/docker-compose.yml`:
    - [ ] PostgreSQL 16 service
    - [ ] Redis 7 service
    - [ ] Qdrant service
    - [ ] Backend service
    - [ ] Frontend service
  - [ ] Create `docker-compose.dev.yml` with hot-reload

- [ ] **1.5 Environment Configuration**
  - [ ] Create `.env.example` with all required variables:
    ```
    # Database
    DATABASE_URL=postgresql+asyncpg://user:pass@localhost:5432/support_agent
    
    # Redis
    REDIS_URL=redis://localhost:6379
    
    # Qdrant
    QDRANT_URL=http://localhost:6333
    QDRANT_API_KEY=
    
    # OpenAI
    OPENAI_API_KEY=
    
    # Cohere
    COHERE_API_KEY=
    
    # JWT
    JWT_SECRET=
    JWT_ALGORITHM=HS256
    ACCESS_TOKEN_EXPIRE_MINUTES=30
    
    # Environment
    ENVIRONMENT=development
    DEBUG=true
    ```
  - [ ] Create `src/core/config.py` with Pydantic BaseSettings

- [ ] **1.6 Database Setup**
  - [ ] Initialize Alembic: `alembic init alembic`
  - [ ] Configure `alembic/env.py` for async SQLAlchemy
  - [ ] Create `src/core/database.py`:
    - [ ] Async engine with connection pooling
    - [ ] `AsyncSessionLocal` factory
    - [ ] `get_db` dependency
    - [ ] Base declarative model

#### Day 3: Core Infrastructure Code

- [ ] **1.7 Redis Client Setup**
  - [ ] Create `src/core/redis.py`:
    - [ ] `RedisClient` singleton class
    - [ ] Async connection with retry
    - [ ] `get_redis_client` dependency

- [ ] **1.8 Logging & Observability**
  - [ ] Create `src/core/logging.py`:
    - [ ] structlog configuration
    - [ ] JSON output for production
    - [ ] Colored console for development
  - [ ] Create `src/core/telemetry.py`:
    - [ ] OpenTelemetry tracer provider
    - [ ] Prometheus metrics reader
    - [ ] Auto-instrumentation (FastAPI, SQLAlchemy, Redis)

- [ ] **1.9 Application Entry Point**
  - [ ] Create `src/main.py`:
    - [ ] FastAPI app with lifespan
    - [ ] CORS middleware
    - [ ] Health check endpoints (`/health`, `/health/live`, `/health/ready`)
    - [ ] Exception handlers
  - [ ] Verify: `docker-compose up` runs without errors

- [ ] **1.10 Validation Checkpoint**
  - [ ] All services start successfully
  - [ ] Health endpoints respond correctly
  - [ ] Database connection works
  - [ ] Redis ping succeeds
  - [ ] Qdrant UI accessible

### Phase 1 Deliverables
- [x] Complete project structure created
- [x] Docker Compose stack running
- [x] Database and cache connections verified
- [x] Health check endpoints functional
- [x] Logging and observability configured

---

## Phase 2: Core Backend Development

### Objectives
- Implement authentication system
- Build chat domain (models, endpoints, repository)
- Set up rate limiting and security middleware
- Create base API structure

### Duration: 5 Days

### Detailed TODO Checklist

#### Day 4: Authentication Domain

- [ ] **2.1 Auth Models**
  - [ ] Create `src/auth/models.py`:
    - [ ] `User` model (id, email, hashed_password, is_active, created_at)
    - [ ] `RefreshToken` model (id, user_id, token, expires_at, revoked)
  - [ ] Create Alembic migration for auth tables

- [ ] **2.2 Auth Schemas**
  - [ ] Create `src/auth/schemas.py`:
    - [ ] `UserCreate`, `UserResponse`
    - [ ] `TokenRequest`, `TokenResponse`
    - [ ] `TokenPayload`

- [ ] **2.3 Auth Service**
  - [ ] Create `src/auth/service.py`:
    - [ ] `create_user()` with password hashing
    - [ ] `authenticate_user()` with password verification
    - [ ] `create_access_token()` with JWT encoding
    - [ ] `create_refresh_token()` with DB storage
    - [ ] `refresh_access_token()` with validation

- [ ] **2.4 Auth Dependencies**
  - [ ] Create `src/auth/dependencies.py`:
    - [ ] `get_current_user()` from JWT token
    - [ ] `get_current_active_user()` with active check
    - [ ] `get_optional_user()` for public endpoints

- [ ] **2.5 Auth Router**
  - [ ] Create `src/auth/router.py`:
    - [ ] `POST /auth/register` - User registration
    - [ ] `POST /auth/token` - Login, return tokens
    - [ ] `POST /auth/refresh` - Refresh access token
    - [ ] `POST /auth/logout` - Revoke refresh token
    - [ ] `GET /auth/me` - Current user info

#### Day 5: Chat Domain Models & Repository

- [ ] **2.6 Chat Models**
  - [ ] Create `src/chat/models.py`:
    - [ ] `MessageRole` enum (user, assistant, system)
    - [ ] `ConversationStatus` enum (active, archived, escalated)
    - [ ] `Conversation` model:
      - id, user_id, title, status, created_at, updated_at
      - metadata (JSON for custom fields)
    - [ ] `Message` model:
      - id, conversation_id, role, content, token_count, created_at
      - feedback (optional rating)
  - [ ] Create Alembic migration

- [ ] **2.7 Chat Schemas**
  - [ ] Create `src/chat/schemas.py`:
    - [ ] `MessageCreate`, `MessageResponse`
    - [ ] `ConversationCreate`, `ConversationResponse`, `ConversationList`
    - [ ] `ChatRequest`, `ChatStreamEvent`
    - [ ] `FeedbackRequest`

- [ ] **2.8 Chat Repository**
  - [ ] Create `src/chat/repository.py`:
    - [ ] `ConversationRepository` class:
      - `get_by_id()` with eager message loading
      - `get_by_user()` with pagination
      - `create()`, `update()`, `delete()`
    - [ ] `MessageRepository` class:
      - `create()`, `get_by_conversation()`
      - `count_tokens()` helper

#### Day 6: Chat Service & REST Endpoints

- [ ] **2.9 Chat Service**
  - [ ] Create `src/chat/service.py`:
    - [ ] `ChatService` class:
      - `create_conversation()` with initial message
      - `get_conversation_history()` formatted for LLM
      - `add_message()` with token counting
      - `update_title()` (auto-generate from first message)
      - `archive_conversation()`

- [ ] **2.10 Chat Dependencies**
  - [ ] Create `src/chat/dependencies.py`:
    - [ ] `valid_conversation()` - Validate ownership
    - [ ] `rate_limit_chat()` - Per-user rate limit

- [ ] **2.11 Chat REST Endpoints**
  - [ ] Create `src/chat/router.py`:
    - [ ] `GET /chat/conversations` - List user conversations
    - [ ] `POST /chat/conversations` - Create new conversation
    - [ ] `GET /chat/conversations/{id}` - Get conversation with messages
    - [ ] `DELETE /chat/conversations/{id}` - Archive conversation
    - [ ] `POST /chat/conversations/{id}/feedback` - Submit feedback

#### Day 7: SSE Streaming & Session Management

- [ ] **2.12 SSE Streaming**
  - [ ] Create `src/chat/streaming.py`:
    - [ ] `SSEResponse` class for Server-Sent Events
    - [ ] `format_sse_event()` helper
    - [ ] `stream_tokens()` async generator
    - [ ] Connection timeout handling

- [ ] **2.13 Session Manager**
  - [ ] Create `src/chat/session_manager.py`:
    - [ ] `ChatSessionManager` class:
      - `create_session()` in Redis
      - `get_session()` with TTL refresh
      - `update_activity()`
      - `invalidate_session()`

- [ ] **2.14 Streaming Endpoint**
  - [ ] Add to `src/chat/router.py`:
    - [ ] `POST /chat/conversations/{id}/stream` - SSE streaming endpoint
    - [ ] Integrate with session manager
    - [ ] Add rate limiting decorator

#### Day 8: Rate Limiting & Security

- [ ] **2.15 Rate Limiting**
  - [ ] Create `src/core/limiter.py`:
    - [ ] SlowAPI limiter with Redis backend
    - [ ] `get_user_identifier()` key function
    - [ ] Default limits: 100/minute general, 20/minute for LLM
  - [ ] Add `SlowAPIMiddleware` to main app
  - [ ] Apply `@limiter.limit()` decorators to endpoints

- [ ] **2.16 Security Middleware**
  - [ ] Create `src/core/middleware.py`:
    - [ ] `RequestLoggingMiddleware` with timing
    - [ ] Request ID injection
    - [ ] Security headers middleware
  - [ ] Configure CORS in main app

- [ ] **2.17 Exception Handling**
  - [ ] Create `src/core/exceptions.py`:
    - [ ] `AppException` base class
    - [ ] Domain-specific exceptions:
      - `ConversationNotFound`
      - `UnauthorizedAccess`
      - `RateLimitExceeded`
      - `LLMServiceError`
  - [ ] Register exception handlers in main app

- [ ] **2.18 Validation Checkpoint**
  - [ ] Auth flow works (register â†’ login â†’ refresh)
  - [ ] Chat CRUD operations functional
  - [ ] Rate limiting enforced
  - [ ] SSE streaming endpoint responds
  - [ ] All tests pass

### Phase 2 Deliverables
- [x] Complete authentication system
- [x] Chat domain with full CRUD
- [x] SSE streaming infrastructure
- [x] Rate limiting and security
- [x] Session management via Redis

---

## Phase 3: RAG Pipeline Implementation

### Objectives
- Set up document ingestion pipeline
- Implement hybrid search (BM25 + dense vectors)
- Configure cross-encoder reranking
- Build query transformation layer

### Duration: 4 Days

### Detailed TODO Checklist

#### Day 9: Document Ingestion Setup

- [ ] **3.1 Install RAG Dependencies**
  - [ ] Add to `pyproject.toml`:
    - [ ] `llama-index`, `llama-index-vector-stores-qdrant`
    - [ ] `llama-index-embeddings-cohere`
    - [ ] `llama-parse` (document parsing)
    - [ ] `cohere` (embeddings + reranking)
    - [ ] `rank-bm25` (sparse retrieval)

- [ ] **3.2 LlamaParse Loader**
  - [ ] Create `src/rag/ingestion/loader.py`:
    - [ ] `DocumentLoader` class:
      - `load_pdf()` with LlamaParse
      - `load_markdown()` for text files
      - `load_docx()` via LlamaParse
      - Metadata extraction (title, author, date)

- [ ] **3.3 Chunking Strategy**
  - [ ] Create `src/rag/ingestion/chunker.py`:
    - [ ] `ChunkingStrategy` enum (recursive, semantic, page)
    - [ ] `RecursiveChunker`:
      - 400 tokens, 80 token overlap
      - Configurable separators
    - [ ] `SemanticChunker`:
      - Sentence embedding comparison
      - Threshold-based splitting
    - [ ] `PageChunker`:
      - PDF page boundaries
      - Metadata preservation

- [ ] **3.4 Embedding Generation**
  - [ ] Create `src/rag/ingestion/embedder.py`:
    - [ ] `CohereEmbedder` class:
      - `embed_documents()` batch embedding
      - `embed_query()` single query embedding
      - Rate limiting and retry logic
      - Dimension: 1024 (Embed-4)

#### Day 10: Vector Store & Indexing

- [ ] **3.5 Qdrant Setup**
  - [ ] Create `src/rag/index.py`:
    - [ ] `QdrantClient` initialization
    - [ ] Collection creation with:
      - Dense vectors (1024 dim, cosine)
      - Sparse vectors for BM25
      - Payload indexes for metadata
    - [ ] Index configuration helper

- [ ] **3.6 Document Uploader**
  - [ ] Create `src/rag/ingestion/uploader.py`:
    - [ ] `VectorUploader` class:
      - `upload_documents()` batch upload
      - `upsert_document()` single doc update
      - `delete_by_metadata()` for updates
      - Parallel upload with asyncio

- [ ] **3.7 Ingestion Pipeline**
  - [ ] Create `src/rag/ingestion/__init__.py`:
    - [ ] `IngestionPipeline` class:
      - `ingest_file()` end-to-end processing
      - `ingest_directory()` batch processing
      - Progress tracking
      - Error handling with retry

- [ ] **3.8 Ingestion CLI**
  - [ ] Create `scripts/ingest_documents.py`:
    - [ ] CLI with argparse
    - [ ] Directory or file input
    - [ ] Chunking strategy selection
    - [ ] Progress bar (tqdm)
    - [ ] Dry-run mode

#### Day 11: Hybrid Retrieval

- [ ] **3.9 Query Transformer**
  - [ ] Create `src/rag/retrieval/query_transformer.py`:
    - [ ] `QueryTransformer` class:
      - `transform_hyde()` - Hypothetical document
      - `transform_multi_query()` - Query variants
      - `transform_step_back()` - Abstraction
    - [ ] Strategy selection based on query type

- [ ] **3.10 Hybrid Retriever**
  - [ ] Create `src/rag/retrieval/hybrid_retriever.py`:
    - [ ] `HybridRetriever` class:
      - Dense retrieval via Qdrant
      - Sparse retrieval via BM25
      - RRF fusion implementation:
        ```python
        def reciprocal_rank_fusion(dense_results, sparse_results, k=60):
            scores = {}
            for rank, doc in enumerate(dense_results):
                scores[doc.id] = scores.get(doc.id, 0) + 1 / (k + rank + 1)
            for rank, doc in enumerate(sparse_results):
                scores[doc.id] = scores.get(doc.id, 0) + 1 / (k + rank + 1)
            return sorted(scores.items(), key=lambda x: x[1], reverse=True)
        ```
      - Alpha parameter for weighting (default 0.5)

- [ ] **3.11 Metadata Filtering**
  - [ ] Create `src/rag/retrieval/metadata_filter.py`:
    - [ ] `MetadataFilter` class:
      - Filter by document type
      - Filter by date range
      - Filter by product/category
      - Filter by language

#### Day 12: Reranking & Pipeline Assembly

- [ ] **3.12 Cohere Reranker**
  - [ ] Create `src/rag/retrieval/reranker.py`:
    - [ ] `CohereReranker` class:
      - `rerank()` with model: rerank-4-multilingual
      - Top-k selection (default 5)
      - Score threshold filtering
      - Batch processing for efficiency

- [ ] **3.13 RAG Pipeline**
  - [ ] Create `src/rag/pipeline.py`:
    - [ ] `RAGPipeline` class:
      - `retrieve()` full pipeline:
        1. Query transformation (if applicable)
        2. Hybrid retrieval (BM25 + dense)
        3. RRF fusion
        4. Metadata filtering
        5. Cross-encoder reranking
        6. Return top-k documents
      - `retrieve_with_scores()` including relevance scores
      - Caching layer for frequent queries

- [ ] **3.14 RAG Evaluation**
  - [ ] Create `src/rag/evaluation.py`:
    - [ ] Install: `ragas`
    - [ ] `RAGEvaluator` class:
      - `evaluate_faithfulness()` - Answer grounded in context
      - `evaluate_context_recall()` - Retrieved relevant docs
      - `evaluate_answer_relevance()` - Answer matches query
    - [ ] Evaluation dataset format

- [ ] **3.15 Validation Checkpoint**
  - [ ] Documents ingest successfully
  - [ ] Hybrid search returns results
  - [ ] Reranking improves relevance
  - [ ] RAGAs scores > 0.85 faithfulness
  - [ ] Query transformation works

### Phase 3 Deliverables
- [x] Document ingestion pipeline (LlamaParse)
- [x] Chunking strategies implemented
- [x] Hybrid retrieval (BM25 + dense + RRF)
- [x] Cohere Rerank-4 integration
- [x] RAGAs evaluation setup

---

## Phase 4: Agent Orchestration (LangGraph)

### Objectives
- Define LangGraph state machine
- Implement specialized agent nodes
- Configure checkpointing for conversation continuity
- Create agent tools

### Duration: 4 Days

### Detailed TODO Checklist

#### Day 13: LangGraph Foundation

- [ ] **4.1 Install Agent Dependencies**
  - [ ] Add to `pyproject.toml`:
    - [ ] `langgraph`, `langchain`, `langchain-openai`
    - [ ] `langchain-cohere`
    - [ ] `langgraph-checkpoint-postgres`

- [ ] **4.2 Agent State Definition**
  - [ ] Create `src/agents/state.py`:
    ```python
    class AgentState(TypedDict):
        # Input
        input: str
        session_id: str
        user_id: str
        language: str
        
        # Messages
        messages: Annotated[List[BaseMessage], add_messages]
        
        # RAG Context
        retrieved_documents: List[Document]
        reranked_documents: List[Document]
        
        # Routing
        query_type: Literal["faq", "complex", "escalation", "out_of_scope"]
        confidence: float
        
        # Output
        response: str
        sources: List[str]
        
        # Metadata
        token_count: int
        processing_time: float
    ```

- [ ] **4.3 PostgreSQL Checkpointer**
  - [ ] Create `src/agents/checkpointer.py`:
    - [ ] Setup `PostgresSaver` from langgraph-checkpoint-postgres
    - [ ] Connection using DATABASE_URL
    - [ ] Thread ID mapping to conversation_id

- [ ] **4.4 Prompt Templates**
  - [ ] Create `src/agents/prompts/system.md`:
    ```markdown
    You are a helpful customer support agent for [Company Name], 
    a Singapore-based SMB. You assist customers with their enquiries
    in a friendly, professional manner.
    
    ## Singapore Context
    - Understand Singlish colloquialisms
    - Aware of local holidays (CNY, Hari Raya, Deepavali)
    - Familiar with SGD currency
    - Know PDPA compliance requirements
    
    ## Guidelines
    - Be concise but thorough
    - Always cite sources when using knowledge base
    - Escalate if customer is frustrated or issue is complex
    - Never make up information
    ```
  - [ ] Create `src/agents/prompts/router.md`
  - [ ] Create `src/agents/prompts/grader.md`
  - [ ] Create `src/agents/prompts/generator.md`

#### Day 14: Agent Nodes Implementation

- [ ] **4.5 Input Node**
  - [ ] Create `src/agents/nodes/input_node.py`:
    - [ ] Language detection (English, Mandarin, Singlish)
    - [ ] Input sanitization
    - [ ] Intent extraction (optional)
    - [ ] Add HumanMessage to state

- [ ] **4.6 Router Node**
  - [ ] Create `src/agents/nodes/router_node.py`:
    - [ ] Query classification:
      - `faq`: Simple, common questions
      - `complex`: Multi-step, needs context
      - `escalation`: Customer frustrated, sensitive
      - `out_of_scope`: Not related to business
    - [ ] Confidence scoring
    - [ ] Use structured output with Pydantic

- [ ] **4.7 Retriever Node**
  - [ ] Create `src/agents/nodes/retriever_node.py`:
    - [ ] Integrate with `RAGPipeline`
    - [ ] Apply query transformation based on query_type
    - [ ] Store retrieved docs in state

- [ ] **4.8 Grader Node**
  - [ ] Create `src/agents/nodes/grader_node.py`:
    - [ ] Score document relevance (0-1)
    - [ ] Filter low-relevance docs (< 0.7)
    - [ ] Decide if web search needed (future)

- [ ] **4.9 Reranker Node**
  - [ ] Create `src/agents/nodes/reranker_node.py`:
    - [ ] Call Cohere Rerank
    - [ ] Select top 5 documents
    - [ ] Update state with reranked docs

#### Day 15: Generator & Tools

- [ ] **4.10 Generator Node**
  - [ ] Create `src/agents/nodes/generator_node.py`:
    - [ ] Build prompt with context and history
    - [ ] Stream response tokens
    - [ ] Extract citations from response
    - [ ] Token counting
    - [ ] Singapore context injection

- [ ] **4.11 Output Node**
  - [ ] Create `src/agents/nodes/output_node.py`:
    - [ ] Format response for API
    - [ ] Attach source citations
    - [ ] Update conversation in database
    - [ ] Trigger memory update

- [ ] **4.12 Agent Tools**
  - [ ] Create `src/agents/tools/knowledge_search.py`:
    - [ ] `@tool` decorator
    - [ ] Searches knowledge base
    - [ ] Returns formatted results
  - [ ] Create `src/agents/tools/escalation.py`:
    - [ ] `@tool` for human escalation
    - [ ] Creates support ticket
    - [ ] Notifies support team
  - [ ] Create `src/agents/tools/order_status.py` (example):
    - [ ] Mock tool for demo
    - [ ] Returns sample order data

#### Day 16: Graph Assembly & Memory

- [ ] **4.13 Graph Construction**
  - [ ] Create `src/agents/graph.py`:
    ```python
    def build_agent_graph():
        workflow = StateGraph(AgentState)
        
        # Add nodes
        workflow.add_node("input", input_node)
        workflow.add_node("router", router_node)
        workflow.add_node("retriever", retriever_node)
        workflow.add_node("grader", grader_node)
        workflow.add_node("reranker", reranker_node)
        workflow.add_node("generator", generator_node)
        workflow.add_node("output", output_node)
        
        # Set entry point
        workflow.set_entry_point("input")
        
        # Add edges
        workflow.add_edge("input", "router")
        workflow.add_conditional_edges(
            "router",
            route_query,
            {
                "faq": "retriever",
                "complex": "retriever",
                "escalation": "output",
                "out_of_scope": "output"
            }
        )
        workflow.add_edge("retriever", "grader")
        workflow.add_edge("grader", "reranker")
        workflow.add_edge("reranker", "generator")
        workflow.add_edge("generator", "output")
        workflow.add_edge("output", END)
        
        return workflow.compile(checkpointer=checkpointer)
    ```

- [ ] **4.14 Memory Management**
  - [ ] Create `src/agents/memory.py`:
    - [ ] `MemoryManager` class:
      - Short-term: Redis (last N messages)
      - Long-term: PostgreSQL (summaries)
      - `get_context()` retrieves relevant history
      - `summarize_conversation()` for long chats

- [ ] **4.15 Streaming Integration**
  - [ ] Create `src/agents/callbacks.py`:
    - [ ] `StreamingCallback` for token streaming
    - [ ] Integrates with SSE endpoint
    - [ ] Handles streaming to WebSocket (optional)

- [ ] **4.16 Validation Checkpoint**
  - [ ] Graph executes end-to-end
  - [ ] Routing works correctly
  - [ ] RAG retrieval integrated
  - [ ] Streaming tokens work
  - [ ] Checkpointing persists state
  - [ ] Memory recall works

### Phase 4 Deliverables
- [x] LangGraph state machine defined
- [x] All agent nodes implemented
- [x] Agent tools created
- [x] PostgreSQL checkpointing
- [x] Memory management (short/long term)
- [x] Streaming callback integration

---

## Phase 5: Frontend Chat Widget

### Objectives
- Build embeddable React chat widget
- Implement SSE streaming display
- Create virtualized message list
- Ensure WCAG accessibility

### Duration: 5 Days

### Detailed TODO Checklist

#### Day 17: Widget Foundation

- [ ] **5.1 Project Setup Verification**
  - [ ] Confirm Vite + React + TypeScript configured
  - [ ] Tailwind CSS + Shadcn/UI installed
  - [ ] Path aliases working (@/components, etc.)

- [ ] **5.2 TypeScript Types**
  - [ ] Create `src/types/chat.ts`:
    ```typescript
    interface Message {
      id: string;
      role: 'user' | 'assistant' | 'system';
      content: string;
      createdAt: Date;
      sources?: Source[];
      isStreaming?: boolean;
    }
    
    interface Source {
      title: string;
      url?: string;
      snippet: string;
    }
    
    interface Conversation {
      id: string;
      title: string;
      messages: Message[];
      createdAt: Date;
      updatedAt: Date;
    }
    ```
  - [ ] Create `src/types/config.ts` for widget config
  - [ ] Create `src/types/api.ts` for API responses

- [ ] **5.3 Zustand Stores**
  - [ ] Create `src/stores/chatStore.ts`:
    ```typescript
    interface ChatState {
      messages: Message[];
      isTyping: boolean;
      currentConversationId: string | null;
      addMessage: (message: Message) => void;
      updateMessage: (id: string, content: string) => void;
      setTyping: (typing: boolean) => void;
      clearMessages: () => void;
    }
    ```
  - [ ] Create `src/stores/uiStore.ts`:
    - Widget open/closed state
    - Theme (light/dark)
    - Error state
  - [ ] Create `src/stores/sessionStore.ts`:
    - Session ID management
    - Auth token storage

#### Day 18: API & SSE Integration

- [ ] **5.4 API Client**
  - [ ] Create `src/lib/api.ts`:
    - [ ] Axios or fetch wrapper
    - [ ] Base URL configuration
    - [ ] Auth header injection
    - [ ] Error handling

- [ ] **5.5 TanStack Query Setup**
  - [ ] Configure QueryClient in `src/App.tsx`
  - [ ] Create query hooks:
    - [ ] `useConversations()` - List conversations
    - [ ] `useConversation(id)` - Single conversation
    - [ ] Mutation: `useCreateConversation()`

- [ ] **5.6 SSE Integration**
  - [ ] Create `src/lib/sse.ts`:
    - [ ] `createSSEConnection()` function
    - [ ] Event parsing
    - [ ] Auto-reconnect logic
    - [ ] Error handling
  - [ ] Create `src/hooks/useChat.ts`:
    - [ ] Wrap Vercel AI SDK's useChat
    - [ ] Configure SSE endpoint
    - [ ] Handle streaming state
    - [ ] Message accumulation

#### Day 19: Chat Components

- [ ] **5.7 Message Components**
  - [ ] Create `src/components/chat/MessageBubble.tsx`:
    - [ ] User message styling (right-aligned)
    - [ ] Assistant message styling (left-aligned)
    - [ ] Markdown rendering via react-markdown
    - [ ] Code block syntax highlighting
    - [ ] Source citations display
  - [ ] Create `src/components/chat/TypingIndicator.tsx`:
    - [ ] Animated dots
    - [ ] Framer Motion animation

- [ ] **5.8 Message List**
  - [ ] Create `src/components/chat/MessageList.tsx`:
    - [ ] react-window VariableSizeList
    - [ ] Dynamic height measurement
    - [ ] `role="log"` for accessibility
    - [ ] `aria-live="polite"`
    - [ ] Auto-scroll to bottom
  - [ ] Create `src/hooks/useVirtualizedList.ts`:
    - [ ] Height caching
    - [ ] `resetAfterIndex()` handling

- [ ] **5.9 Input Area**
  - [ ] Create `src/components/chat/InputArea.tsx`:
    - [ ] Textarea with auto-resize
    - [ ] Send button with loading state
    - [ ] Enter to send, Shift+Enter for newline
    - [ ] Character limit indicator
    - [ ] Disabled state during streaming

#### Day 20: Widget Container & Trigger

- [ ] **5.10 Chat Widget Container**
  - [ ] Create `src/components/chat/ChatWidget.tsx`:
    - [ ] Widget panel layout (header, messages, input)
    - [ ] Open/close animation (Framer Motion)
    - [ ] Mobile responsive (full-screen on small devices)
    - [ ] Shadow DOM container for style isolation

- [ ] **5.11 Chat Header**
  - [ ] Create `src/components/chat/ChatHeader.tsx`:
    - [ ] Company logo/title
    - [ ] Status indicator (online/offline)
    - [ ] Close button
    - [ ] Minimize option

- [ ] **5.12 Chat Trigger**
  - [ ] Create `src/components/chat/ChatTrigger.tsx`:
    - [ ] Floating action button
    - [ ] Unread message badge
    - [ ] Pulse animation on new message
    - [ ] Accessible labeling

- [ ] **5.13 Quick Replies**
  - [ ] Create `src/components/chat/QuickReplies.tsx`:
    - [ ] Suggested response buttons
    - [ ] Keyboard navigation
    - [ ] Dynamic based on context

#### Day 21: Accessibility & Widget Build

- [ ] **5.14 Accessibility Audit**
  - [ ] WCAG 2.2 compliance:
    - [ ] Focus management (trap focus in open widget)
    - [ ] Keyboard navigation (Tab, Escape to close)
    - [ ] Screen reader testing
    - [ ] `aria-live` regions for streaming
    - [ ] Color contrast (AA minimum)
    - [ ] Touch target size (24x24 minimum)
  - [ ] Skip link to chat widget
  - [ ] Sender identification text

- [ ] **5.15 Widget Entry Point**
  - [ ] Create `src/widget.tsx`:
    - [ ] Shadow DOM creation
    - [ ] Style injection
    - [ ] Config parsing from data attributes
    - [ ] Mount React app to shadow root

- [ ] **5.16 Widget Loader Script**
  - [ ] Create `public/widget-loader.js`:
    - [ ] Script tag configuration parsing
    - [ ] Dynamic script loading
    - [ ] Initialization function
    ```javascript
    (function() {
      const script = document.currentScript;
      const clientKey = script.getAttribute('data-client-key');
      const theme = script.getAttribute('data-theme') || 'light';
      
      // Load main widget bundle
      const widgetScript = document.createElement('script');
      widgetScript.src = 'https://cdn.example.com/widget.js';
      widgetScript.onload = function() {
        window.SupportWidget.init({ clientKey, theme });
      };
      document.body.appendChild(widgetScript);
    })();
    ```

- [ ] **5.17 Build Configuration**
  - [ ] Update `vite.config.ts`:
    - [ ] Library mode build
    - [ ] UMD + ESM output
    - [ ] CSS extraction for Shadow DOM
    - [ ] Sourcemaps for production
  - [ ] Test: Widget embeds correctly in test HTML

- [ ] **5.18 Validation Checkpoint**
  - [ ] Widget opens/closes smoothly
  - [ ] Messages stream correctly
  - [ ] Markdown renders properly
  - [ ] Mobile responsive
  - [ ] Accessibility audit passes
  - [ ] Embeds in external page

### Phase 5 Deliverables
- [x] Complete React chat widget
- [x] SSE streaming display
- [x] Virtualized message list
- [x] WCAG 2.2 accessible
- [x] Embeddable via script tag
- [x] Mobile responsive

---

## Phase 6: Integration & Testing

### Objectives
- Full end-to-end integration testing
- Performance optimization
- Security audit
- Documentation completion

### Duration: 3 Days

### Detailed TODO Checklist

#### Day 22: Integration Testing

- [ ] **6.1 API Integration Tests**
  - [ ] Create `tests/integration/test_api_chat.py`:
    - [ ] Test conversation creation
    - [ ] Test message sending
    - [ ] Test SSE streaming response
    - [ ] Test error handling
  - [ ] Create `tests/integration/test_rag_pipeline.py`:
    - [ ] Test document retrieval
    - [ ] Test hybrid search
    - [ ] Test reranking

- [ ] **6.2 Agent Integration Tests**
  - [ ] Create `tests/integration/test_agent_graph.py`:
    - [ ] Test graph execution
    - [ ] Test routing logic
    - [ ] Test checkpointing
    - [ ] Test tool execution

- [ ] **6.3 E2E Tests**
  - [ ] Create `tests/e2e/test_full_conversation.py`:
    - [ ] Complete user journey
    - [ ] Multi-turn conversation
    - [ ] Context retention
    - [ ] Escalation flow

- [ ] **6.4 Frontend Tests**
  - [ ] Set up Vitest for frontend
  - [ ] Component tests:
    - [ ] MessageBubble rendering
    - [ ] Chat state management
    - [ ] SSE handling

#### Day 23: Performance & Security

- [ ] **6.5 Performance Optimization**
  - [ ] Backend:
    - [ ] Database query optimization (EXPLAIN ANALYZE)
    - [ ] Connection pooling tuning
    - [ ] Caching strategy review
    - [ ] Response compression
  - [ ] Frontend:
    - [ ] Bundle size analysis (vite-bundle-analyzer)
    - [ ] Code splitting verification
    - [ ] Lighthouse performance audit

- [ ] **6.6 Load Testing**
  - [ ] Create `scripts/load_test.py`:
    - [ ] Use locust or k6
    - [ ] Test concurrent connections
    - [ ] Test SSE streaming under load
    - [ ] Identify bottlenecks

- [ ] **6.7 Security Audit**
  - [ ] Authentication:
    - [ ] JWT expiration enforced
    - [ ] Refresh token rotation
    - [ ] Rate limiting effective
  - [ ] API:
    - [ ] Input validation comprehensive
    - [ ] SQL injection prevention
    - [ ] XSS prevention (Markdown sanitization)
  - [ ] Dependencies:
    - [ ] Run `pip-audit` for Python
    - [ ] Run `npm audit` for frontend

#### Day 24: Documentation

- [ ] **6.8 API Documentation**
  - [ ] Create `docs/api-reference.md`:
    - [ ] All endpoints documented
    - [ ] Request/response examples
    - [ ] Error codes reference
  - [ ] Verify OpenAPI spec (FastAPI auto-generated)

- [ ] **6.9 Deployment Documentation**
  - [ ] Create `docs/deployment-guide.md`:
    - [ ] Environment setup
    - [ ] Docker deployment
    - [ ] Environment variables
    - [ ] Database migrations
    - [ ] Monitoring setup

- [ ] **6.10 Configuration Documentation**
  - [ ] Create `docs/configuration.md`:
    - [ ] All configuration options
    - [ ] Feature flags
    - [ ] Scaling recommendations

- [ ] **6.11 Widget Integration Guide**
  - [ ] Add to `docs/widget-integration.md`:
    - [ ] Installation instructions
    - [ ] Configuration options
    - [ ] Customization (themes, styling)
    - [ ] Event hooks

### Phase 6 Deliverables
- [x] Integration tests passing
- [x] E2E tests passing
- [x] Performance optimized
- [x] Security audit complete
- [x] Documentation complete

---

## Phase 7: Deployment & Monitoring

### Objectives
- Production deployment
- Monitoring and alerting setup
- Knowledge base seeding
- Handover documentation

### Duration: 4 Days

### Detailed TODO Checklist

#### Day 25: Production Infrastructure

- [ ] **7.1 Production Docker Compose**
  - [ ] Create `docker-compose.prod.yml`:
    - [ ] Production environment variables
    - [ ] Resource limits
    - [ ] Restart policies
    - [ ] Health checks

- [ ] **7.2 Database Setup**
  - [ ] Run Alembic migrations: `alembic upgrade head`
  - [ ] Create production database user
  - [ ] Configure backup schedule
  - [ ] Set up connection pooling (pgBouncer optional)

- [ ] **7.3 Qdrant Cloud Setup**
  - [ ] Create Qdrant Cloud cluster
  - [ ] Configure API key
  - [ ] Create collections with proper indexes
  - [ ] Verify hybrid search enabled

#### Day 26: Monitoring Setup

- [ ] **7.4 Prometheus Configuration**
  - [ ] Create `infra/monitoring/prometheus/prometheus.yml`
  - [ ] Configure scrape targets:
    - [ ] FastAPI metrics endpoint
    - [ ] PostgreSQL exporter
    - [ ] Redis exporter

- [ ] **7.5 Grafana Dashboards**
  - [ ] Create `infra/monitoring/grafana/dashboards/`:
    - [ ] `api-dashboard.json`:
      - Request rate
      - Latency percentiles
      - Error rate
      - Status code distribution
    - [ ] `llm-dashboard.json`:
      - Token usage
      - LLM latency
      - Cost tracking
      - Error rate

- [ ] **7.6 Alerting Rules**
  - [ ] Configure alerts for:
    - [ ] High error rate (> 1%)
    - [ ] High latency (p95 > 5s)
    - [ ] Database connection errors
    - [ ] LLM service unavailable

#### Day 27: Knowledge Base & Testing

- [ ] **7.7 Knowledge Base Seeding**
  - [ ] Prepare sample documents:
    - [ ] FAQs (general, billing, technical)
    - [ ] Product catalog
    - [ ] Policies (privacy, terms)
  - [ ] Run ingestion: `python scripts/ingest_documents.py ./knowledge_base/`
  - [ ] Verify documents in Qdrant

- [ ] **7.8 RAG Evaluation**
  - [ ] Create evaluation dataset (20+ Q&A pairs)
  - [ ] Run: `python scripts/evaluate_rag.py`
  - [ ] Verify:
    - [ ] Faithfulness > 0.85
    - [ ] Context Recall > 0.80
    - [ ] Answer Relevance > 0.90

- [ ] **7.9 Production Testing**
  - [ ] Smoke tests in production environment
  - [ ] Multi-turn conversation test
  - [ ] Escalation flow test
  - [ ] Load test (10 concurrent users)

#### Day 28: Launch & Handover

- [ ] **7.10 Final Deployment**
  - [ ] Deploy backend: `docker-compose -f docker-compose.prod.yml up -d`
  - [ ] Deploy frontend widget to CDN
  - [ ] Verify health endpoints
  - [ ] Verify monitoring dashboards

- [ ] **7.11 Widget Integration**
  - [ ] Generate client API key
  - [ ] Provide embed code:
    ```html
    <script
      src="https://cdn.example.com/widget-loader.js"
      data-client-key="YOUR_API_KEY"
      data-theme="light"
    ></script>
    ```
  - [ ] Test on target website

- [ ] **7.12 Handover Documentation**
  - [ ] Update `README.md` with:
    - [ ] Quick start guide
    - [ ] Architecture overview
    - [ ] Development setup
    - [ ] Deployment instructions
  - [ ] Create `docs/troubleshooting.md`:
    - [ ] Common issues
    - [ ] Debug procedures
    - [ ] Support contacts

- [ ] **7.13 Final Validation**
  - [ ] All tests passing
  - [ ] Monitoring operational
  - [ ] Documentation complete
  - [ ] Stakeholder sign-off

### Phase 7 Deliverables
- [x] Production deployment live
- [x] Monitoring and alerting operational
- [x] Knowledge base populated
- [x] Widget embeddable
- [x] Complete documentation

---

## 8. Success Metrics & Validation

### Technical Metrics

| Metric | Target | Measurement |
|--------|--------|-------------|
| API Latency (p95) | < 500ms | Prometheus histogram |
| LLM Response Time (p95) | < 5s | Custom metric |
| Uptime | > 99.5% | Health check monitoring |
| Error Rate | < 1% | Error counter |
| RAGAs Faithfulness | > 0.85 | Evaluation script |
| RAGAs Context Recall | > 0.80 | Evaluation script |

### Business Metrics (Post-Launch)

| Metric | Target | Measurement |
|--------|--------|-------------|
| Customer Satisfaction | > 4.0/5 | In-widget feedback |
| Query Resolution Rate | > 70% | Escalation rate inverse |
| Avg Response Time | < 3s | End-to-end timing |
| Daily Active Users | Growth | Analytics |

### Validation Checkpoints

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         VALIDATION GATES                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  âœ“ Phase 1 Complete: Infrastructure running, health checks pass         â”‚
â”‚                                                                          â”‚
â”‚  âœ“ Phase 2 Complete: Auth works, Chat CRUD functional, SSE streams     â”‚
â”‚                                                                          â”‚
â”‚  âœ“ Phase 3 Complete: RAG retrieval accurate, reranking improves results â”‚
â”‚                                                                          â”‚
â”‚  âœ“ Phase 4 Complete: Agent graph executes, checkpointing works         â”‚
â”‚                                                                          â”‚
â”‚  âœ“ Phase 5 Complete: Widget embeds, accessible, mobile responsive       â”‚
â”‚                                                                          â”‚
â”‚  âœ“ Phase 6 Complete: All tests pass, security audit clean              â”‚
â”‚                                                                          â”‚
â”‚  âœ“ Phase 7 Complete: Production live, monitoring operational            â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Appendix A: Environment Variables Reference

```bash
# =============================================================================
# CORE APPLICATION
# =============================================================================
ENVIRONMENT=production          # development | staging | production
DEBUG=false                     # Enable debug mode
LOG_LEVEL=INFO                  # DEBUG | INFO | WARNING | ERROR

# =============================================================================
# DATABASE
# =============================================================================
DATABASE_URL=postgresql+asyncpg://user:password@host:5432/dbname
DB_POOL_SIZE=20
DB_MAX_OVERFLOW=10
DB_POOL_RECYCLE=3600

# =============================================================================
# REDIS
# =============================================================================
REDIS_URL=redis://localhost:6379/0
REDIS_MAX_CONNECTIONS=20

# =============================================================================
# VECTOR DATABASE (QDRANT)
# =============================================================================
QDRANT_URL=https://your-cluster.qdrant.io
QDRANT_API_KEY=your-api-key
QDRANT_COLLECTION=support_docs

# =============================================================================
# LLM PROVIDERS
# =============================================================================
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4-turbo

# =============================================================================
# COHERE (EMBEDDINGS + RERANKING)
# =============================================================================
COHERE_API_KEY=your-cohere-key
COHERE_EMBED_MODEL=embed-english-v3.0
COHERE_RERANK_MODEL=rerank-v3.5

# =============================================================================
# AUTHENTICATION
# =============================================================================
JWT_SECRET=your-super-secret-key-min-32-chars
JWT_ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30
REFRESH_TOKEN_EXPIRE_DAYS=30

# =============================================================================
# RATE LIMITING
# =============================================================================
RATE_LIMIT_DEFAULT=100/minute
RATE_LIMIT_LLM=20/minute

# =============================================================================
# CORS
# =============================================================================
CORS_ORIGINS=["https://yourdomain.com", "https://app.yourdomain.com"]

# =============================================================================
# OBSERVABILITY
# =============================================================================
OTEL_EXPORTER_OTLP_ENDPOINT=http://jaeger:4317
PROMETHEUS_MULTIPROC_DIR=/tmp/prometheus
```

---

## Appendix B: Cost Estimation (Monthly)

| Service | Tier | Estimated Cost (SGD) |
|---------|------|---------------------|
| **Qdrant Cloud** | 1GB free, then $25/mo | ~$35 |
| **PostgreSQL** | DigitalOcean Managed | ~$15 |
| **Redis** | DigitalOcean Managed | ~$15 |
| **OpenAI GPT-4** | ~100K tokens/day | ~$60 |
| **Cohere Embed** | ~50K docs embedded | ~$10 |
| **Cohere Rerank** | ~10K reranks/day | ~$15 |
| **Compute (VPS)** | 4GB RAM, 2 vCPU | ~$25 |
| **CDN (Widget)** | Cloudflare Free | $0 |
| **TOTAL** | | **~$175/month** |

*Note: Costs vary based on usage. Optimize with caching and batch operations.*

---

## Appendix C: Quick Reference Commands

```bash
# Development
make dev                    # Start development stack
make test                   # Run all tests
make lint                   # Run linters
make migrate                # Run database migrations

# Docker
docker-compose up -d        # Start all services
docker-compose logs -f api  # Follow API logs
docker-compose down         # Stop all services

# Database
alembic upgrade head        # Apply migrations
alembic revision -m "msg"   # Create new migration
alembic downgrade -1        # Rollback one migration

# RAG
python scripts/ingest_documents.py ./docs/  # Ingest documents
python scripts/evaluate_rag.py              # Run RAGAs evaluation

# Production
docker-compose -f docker-compose.prod.yml up -d  # Deploy production
docker-compose -f docker-compose.prod.yml logs   # View logs
```

---

**Document End**

*This Master Execution Plan is ready for implementation. Each phase can be executed independently after its dependencies are complete. Refer to the validation checkpoints at the end of each phase to ensure quality before proceeding.*
# **DEEP ANALYSIS & VALIDATION OF EXECUTION PLAN & CRITIQUE**

## **Phase 1: Request Analysis & Planning**

### **1.1 Deep Understanding**
**Objective**: Validate the provided execution plan critique against the extensive research documentation, identifying both accurate insights and potential misinterpretations.

**Multi-dimensional analysis lens**:
- *Psychological*: Singapore SMB owners need confidence in AI reliability, not just technical correctness
- *Technical*: Framework trade-offs between LangGraph stability vs Pydantic AI type safety
- *Accessibility*: WCAG 2.2 requirements for customer-facing chat widgets
- *Scalability*: Long-term maintenance implications of framework choices

**Core question**: Does the critique correctly balance cutting-edge research with production pragmatism for a Singapore SMB context?

### **1.2 Research Synthesis**
Having thoroughly analyzed all six research documents (263 pages total), I've identified key alignment points and potential contradictions:

**Document Key Insights**:
1. **FastAPI Best Practices**: Domain-driven structure, SSE for streaming, PostgreSQL checkpointer for state
2. **LangGraph/LangChain**: State machine patterns, interrupt-driven human-in-loop, production-ready
3. **Pydantic AI**: Type-safe agents, built-in validation, dependency injection system
4. **RAG Best Practices**: Hybrid search, RRF fusion, Qdrant vs competitors, multilingual reranking
5. **React Chat Interfaces**: SSE over WebSockets, Zustand+TanStack Query, virtualized lists
6. **Execution Plan Critique**: Validates plan, recommends Pydantic AI, stronger evaluation

### **1.3 Critical Observations Before Validation**

The critique makes **bold framework recommendations** that require careful examination:
- Pydantic AI recommendation contradicts established LangGraph patterns in research
- Framework migration implications could derail 28-day timeline
- Singapore SMB constraints (budget, timeline, multilingual) must dominate all decisions

## **Phase 2: Structured Validation & Critique**

### **2.1 Agent Framework Selection Analysis**

**Critique Claim**: "The plan uses LangChain/LangGraph but completely misses Pydantic AI framework"

**My Assessment**: **Partially Correct, but Misses Critical Context**

**Research Evidence**:
1. **Pydantic AI Document** (Section 7): "Pydantic AI and LangChain serve different architectural philosophies but can complement each other. LangChain provides a comprehensive ecosystem with pre-built chains, memory modules, and extensive integrations."
   
2. **LangGraph Document** (Section 2.1): "LangGraph has become the foundation for building reliable AI agent workflows in 2025. Unlike simple chain-based approaches, LangGraph models agent workflows as directed graphs where nodes represent processing steps."

**The Problem with the Critique**:
- **Overstates Pydantic AI's production readiness**: The research shows LangGraph's checkpointing, interrupt patterns, and state management are battle-tested
- **Ignores LangGraph's human-in-the-loop capabilities**: Critical for Singapore SMB customer support escalation
- **Misinterprets "framework" vs "validation layer"**: Pydantic AI excels at validation, not complete agent orchestration

**Singapore SMB Reality Check**:
- Day 1 requirements: Multilingual support, PDPA compliance, escalation workflows
- LangGraph provides: Built-in state persistence, interrupt patterns, tool execution
- Pydantic AI provides: Type safety, dependency injection, structured outputs

**My Recommendation**: **Hybrid Architecture**

```python
# CORRECT: Use LangGraph for orchestration, Pydantic AI for validation
from langgraph.graph import StateGraph, END
from pydantic_ai import Agent, RunContext
from typing import TypedDict, Annotated

class ValidatedState(TypedDict):
    # LangGraph state with Pydantic validation
    query: str
    customer_id: str
    validated_output: dict  # Pydantic-validated output

# Use Pydantic AI within LangGraph nodes for validation
def validate_with_pydantic(state: ValidatedState) -> dict:
    """Use Pydantic AI for structured output validation"""
    customer_agent = Agent(
        'anthropic:claude-sonnet-4-0',
        deps_type=CustomerServiceDeps,
        output_type=CustomerServiceResult,
        retries=2
    )
    
    result = customer_agent.run_sync(state['query'])
    return {"validated_output": result.output.dict()}
```

### **2.2 RAG Evaluation Strategy Analysis**

**Critique Claim**: "The plan mentions RAGAs evaluation but lacks concrete metrics thresholds"

**My Assessment**: **Mostly Correct, But Needs Singapore-Specific Adjustments**

**Research Evidence**:
1. **RAG Document** (Section 10.4): "RAGAs (Retrieval-Augmented Generation Assessment) provides reference-free evaluation of RAG pipelines, leveraging LLMs to automatically assess quality without requiring human-written ground-truth answers."

2. **Singapore SMB Section** (11.3): "Deploy RAGAs for continuous evaluation with focus on: Faithfulness threshold: >0.85, Context Recall target: >0.80, Answer Relevance target: >0.90"

**The Critique is Correct On**:
- Concrete thresholds are essential for production
- Continuous evaluation prevents degradation
- Fallback mechanisms needed

**What's Missing in the Critique**:
- **Singapore multilingual considerations**: RAGAs benchmarks are English-focused
- **Cost implications**: Daily evaluation of large knowledge bases is expensive
- **Sampling strategy**: Should evaluate high-traffic queries more frequently

**Enhanced Recommendation**:

```python
# Singapore-optimized RAG evaluation
def evaluate_rag_singapore(knowledge_base: List[Document], 
                          sample_rate: float = 0.1) -> Dict[str, float]:
    """
    Evaluate RAG with Singapore-specific considerations:
    1. Multilingual query sampling
    2. PDPA-sensitive content filtering
    3. Cost-optimized evaluation frequency
    """
    
    # Sample multilingual queries based on traffic patterns
    queries = sample_queries_by_language(
        ['en', 'zh', 'ms', 'ta'],  # Singapore official languages
        traffic_weights=[0.6, 0.25, 0.1, 0.05]
    )
    
    # Evaluate with cost-aware batching
    metrics = evaluate_with_ragas(
        queries,
        knowledge_base,
        metrics=['faithfulness', 'answer_relevance', 'context_recall'],
        # Lower temperature for Singapore factual accuracy
        llm_settings={'temperature': 0.1}
    )
    
    # Singapore-specific thresholds
    return {
        'faithfulness': metrics.faithfulness > 0.82,  # Slightly lower for multilingual
        'answer_relevance': metrics.answer_relevance > 0.88,
        'context_recall': metrics.context_recall > 0.78,
        'multilingual_coverage': calculate_language_coverage(metrics)
    }
```

### **2.3 Production Observability Analysis**

**Critique Claim**: "The plan includes monitoring but lacks specific LLM-specific metrics"

**My Assessment**: **Correct, But Underestimates Singapore Compliance Requirements**

**Research Evidence**:
1. **FastAPI Document** (Section 11.2): "OpenTelemetry integration enables real-time tracing and metrics for LLM operations, including token usage and latency."

2. **Singapore Context**: PDPA (Personal Data Protection Act) requires audit trails for customer data handling.

**What the Critique Gets Right**:
- LLM-specific metrics are essential
- Cost tracking prevents budget overruns
- Alerting thresholds needed

**Critical Singapore-Specific Gaps**:

```python
# PDPA-compliant observability
class SingaporeCompliantMetrics:
    """Metrics system meeting Singapore PDPA requirements"""
    
    def __init__(self):
        self.meter = meter
        # PDPA: Must not log actual customer queries
        self.query_counter = self.meter.create_counter(
            "customer_queries_total",
            description="Count of customer queries (anonymized)"
        )
        
        # PDPA: Must track data access for audit
        self.data_access_counter = self.meter.create_counter(
            "customer_data_access_events",
            description="Audit trail of customer data access"
        )
        
        # Singapore-specific: Multilingual performance
        self.language_histogram = self.meter.create_histogram(
            "response_time_by_language",
            description="Response time segmented by query language"
        )
    
    def record_query(self, query_hash: str, language: str):
        """Record query without storing actual content (PDPA compliance)"""
        self.query_counter.add(1, {
            "language": language,
            "query_hash": query_hash[:8]  # Anonymized
        })
```

### **2.4 Frontend Streaming Performance Analysis**

**Critique Claim**: "The plan implements streaming but lacks performance optimization"

**My Assessment**: **Correct and Well-Documented**

**Research Evidence**:
1. **React Chat Document** (Section 7.2): "ChatGPT achieves smooth streaming through several optimizations: batching multiple tokens before state updates, using refs to store intermediate values, implementing virtualization."

2. **Singapore Mobile Considerations**: 92% of Singaporeans use smartphones, requiring mobile-optimized streaming.

**The Critique's Solution is Good, But Needs Mobile Enhancement**:

```typescript
// Mobile-optimized streaming for Singapore (high smartphone usage)
const useMobileOptimizedStream = (text: string, isMobile: boolean) => {
  const [displayedText, setDisplayedText] = useState('');
  const textRef = useRef(text);
  const isStreamingRef = useRef(false);
  const animationFrameRef = useRef<number>();

  const streamText = useCallback(() => {
    if (isStreamingRef.current || text.length <= displayedText.length) return;
    
    isStreamingRef.current = true;
    textRef.current = text;
    let currentIndex = displayedText.length;
    
    const update = () => {
      if (currentIndex < textRef.current.length) {
        // Mobile: Smaller batches for lower-end devices
        const batchSize = isMobile ? 3 : 5;
        const nextChunk = textRef.current.slice(
          currentIndex, 
          currentIndex + batchSize
        );
        
        // Use animation frame for smooth mobile rendering
        setDisplayedText(prev => prev + nextChunk);
        currentIndex += batchSize;
        
        // Mobile: Adjust timing for perceived performance
        const speed = isMobile ? 70 : 50;
        setTimeout(update, speed);
      } else {
        isStreamingRef.current = false;
        if (animationFrameRef.current) {
          cancelAnimationFrame(animationFrameRef.current);
        }
      }
    };
    
    // Start on animation frame for smooth initiation
    animationFrameRef.current = requestAnimationFrame(update);
  }, [text, displayedText, isMobile]);

  return { displayedText, streamText };
};
```

## **Phase 3: Gap Analysis & Risk Assessment**

### **3.1 Critical Missing Components in Both Plan and Critique**

**Singapore Regulatory Compliance**:
- **PDPA Implementation**: Neither document specifies how personal data flows through the RAG system
- **Audit Trail Requirements**: Singapore requires 6-year retention of financial advice records
- **Multilingual Consent**: Consent must be obtained in customer's preferred language

**Cost Optimization for SMB**:
- **Missing**: Staggered model usage (small models for simple queries, large for complex)
- **Missing**: Query caching strategy for frequent questions
- **Missing**: Rate limiting per customer tier (premium vs standard)

**Disaster Recovery**:
- **Missing**: RAG fallback when vector database is unavailable
- **Missing**: LLM fallback chains (Cohere â†’ OpenAI â†’ self-hosted)

### **3.2 Architecture Risk Assessment**

| Risk | Severity | Mitigation |
|------|----------|------------|
| **LangGraph â†’ Pydantic AI migration** | High | Use Pydantic AI for validation only, not orchestration |
| **Multilingual RAG quality** | High | Implement language-specific chunking and evaluation |
| **Singapore PDPA compliance** | Critical | Build anonymization into metrics from day 1 |
| **28-day timeline** | Medium | Prioritize core customer support flows first |
| **Cost overruns** | Medium | Implement strict usage limits and alerts |

### **3.3 Framework Decision Matrix**

Based on research, here's the optimal framework selection:

```python
FRAMEWORK_DECISION = {
    "orchestration": "LangGraph",  # Production-ready, state management
    "validation": "Pydantic AI",   # Type safety, structured outputs
    "retrieval": "LlamaIndex",     # 40% faster retrieval (RAG research)
    "vector_db": "Qdrant",         # SOC2 compliance, hybrid search
    "frontend": {
        "state": "Zustand + TanStack Query",
        "streaming": "SSE via Vercel AI SDK",
        "components": "Shadcn/UI + assistant-ui"
    },
    "rationale": {
        "LangGraph_over_PydanticAI": "Checkpointing, interrupts, production patterns",
        "LlamaIndex_over_LangChain": "Faster retrieval for RAG (40% benchmark)",
        "SSE_over_WebSocket": "Unidirectional streaming sufficient for chat"
    }
}
```

## **Phase 4: Enhanced Recommendations**

### **4.1 Singapore-Specific Implementation Pattern**

```python
# Singapore SMB customer support agent
class SingaporeCustomerSupportAgent:
    """Production agent with Singapore-specific considerations"""
    
    def __init__(self):
        # LangGraph for orchestration
        self.workflow = StateGraph(AgentState)
        
        # Pydantic AI for validation within nodes
        self.validator = Agent(
            'anthropic:claude-sonnet-4-0',
            deps_type=CustomerServiceDeps,
            output_type=CustomerServiceResult,
            system_prompt=self._singapore_system_prompt()
        )
        
        # Singapore-specific tools
        self.tools = [
            self._check_pdpa_compliance,
            self._detect_singlish,
            self._handle_multilingual_query,
            self._escalate_to_human_singapore
        ]
    
    def _singapore_system_prompt(self) -> str:
        return """
        You are a customer support assistant for a Singapore Small Business.
        
        SINGAPORE-SPECIFIC GUIDELINES:
        1. Address customers formally (Mr/Ms) unless they specify otherwise
        2. Be aware of Singapore public holidays and business hours
        3. Understand Singlish terms but respond in proper English
        4. Never store personal data without explicit consent (PDPA)
        5. For financial advice, always recommend consulting a qualified professional
        6. Escalate to human agent if query involves legal or financial risk
        
        MULTILINGUAL SUPPORT:
        - Primary: English
        - Secondary: Mandarin, Malay, Tamil
        - Code-switching is common (Singlish) - understand context
        
        BUSINESS CONTEXT:
        - Singapore SMBs often family-run
        - Prefer practical, cost-effective solutions
        - Value quick resolution over extensive explanations
        """
```

### **4.2 Enhanced RAG Evaluation for Singapore**

```python
def singapore_rag_evaluation_pipeline(
    knowledge_base: List[Document],
    evaluation_budget: float = 100.0  # Monthly budget in SGD
) -> EvaluationResults:
    """
    Cost-aware RAG evaluation for Singapore SMB budget constraints
    """
    
    # 1. Priority-based sampling
    queries = sample_queries(
        method='traffic_weighted',
        min_coverage=0.8,
        max_cost=evaluation_budget * 0.7  # Reserve 30% for re-evaluation
    )
    
    # 2. Language-stratified evaluation
    results = {}
    for lang in ['en', 'zh', 'ms', 'ta']:
        lang_queries = [q for q in queries if q.language == lang]
        if lang_queries:
            results[lang] = evaluate_language_specific(
                lang_queries,
                knowledge_base,
                # Language-specific thresholds
                faithfulness_threshold=0.82 if lang == 'en' else 0.78,
                # Adjust for language complexity
                cost_limit=evaluation_budget * language_weight(lang)
            )
    
    # 3. Continuous improvement loop
    improvement_plan = generate_improvement_plan(
        results,
        budget_remaining=evaluation_budget * 0.3
    )
    
    return EvaluationResults(
        overall_score=weighted_average(results),
        language_breakdown=results,
        improvement_plan=improvement_plan,
        cost_used=calculate_cost_used(queries)
    )
```

### **4.3 Production Observability with PDPA Compliance**

```python
# Singapore PDPA-compliant observability
@singleton
class PDPACompliantMonitor:
    """Monitoring that never stores personal data"""
    
    def __init__(self):
        # Anonymized metrics only
        self.metrics = {
            'query_volume': Counter('queries_total', 'Total queries'),
            'response_time': Histogram('response_seconds', 'Response time'),
            'language_distribution': Gauge('queries_by_language', 'Query language'),
            'cost_tracking': Gauge('cost_sgd', 'Cost in SGD'),
        }
        
        # PDPA: Hash queries for tracking without storage
        self.query_hasher = hashlib.sha256
    
    def record_query(self, query: str, customer_id: str) -> str:
        """Record query without storing personal data"""
        query_hash = self.query_hasher(query.encode()).hexdigest()[:16]
        customer_hash = self.query_hasher(customer_id.encode()).hexdigest()[:8]
        
        # Store only hashes
        self.metrics['query_volume'].inc(
            1, 
            {'query_hash': query_hash, 'customer_hash': customer_hash}
        )
        
        return query_hash
    
    def generate_audit_trail(self, query_hash: str) -> AuditTrail:
        """Generate PDPA-compliant audit trail"""
        return {
            'timestamp': datetime.utcnow().isoformat(),
            'query_hash': query_hash,
            'actions_taken': [],  # List of system actions
            'data_accessed': [],  # Which knowledge base sections
            'llm_usage': {       # Token usage for cost tracking
                'prompt_tokens': 0,
                'completion_tokens': 0,
                'estimated_cost_sgd': 0.0
            }
        }
```

## **Phase 5: Final Validation & Recommendations**

### **5.1 Validation Scorecard**

| Component | Plan Status | Critique Accuracy | My Recommendation |
|-----------|------------|-------------------|-------------------|
| **Agent Framework** | LangGraph âœ… | âš ï¸ Partial (misses hybrid approach) | LangGraph + Pydantic AI validation |
| **RAG Pipeline** | Qdrant + Cohere âœ… | âœ… Mostly correct | Add multilingual sampling |
| **Frontend** | React + Zustand âœ… | âœ… Correct | Add mobile optimization |
| **Observability** | Basic âŒ | âœ… Correct | Add PDPA compliance |
| **Singapore Compliance** | Missing âŒ | Missing âŒ | Add PDPA, multilingual, audit trails |
| **Cost Optimization** | Basic âŒ | Partial âš ï¸ | Add tiered models, caching |

### **5.2 Critical Corrections to the Critique**

1. **Pydantic AI vs LangGraph**: The critique overstates Pydantic AI's capabilities. Use LangGraph for orchestration with Pydantic AI for validation.

2. **Timeline Implications**: Framework migration would add 7-10 days to timeline. Not feasible for 28-day delivery.

3. **Singapore Specifics**: Both plan and critique miss critical Singapore requirements (PDPA, multilingual, Singlish).

### **5.3 Final Recommendations**

**Immediate Actions (Week 1)**:
1. **Don't change framework**: Stick with LangGraph for orchestration
2. **Add Pydantic AI** as validation layer within LangGraph nodes
3. **Implement PDPA-compliant metrics** from day 1
4. **Set up multilingual RAG evaluation** with language-specific thresholds

**Singapore-Specific Requirements**:
1. **PDPA Compliance Layer**: All customer data hashed, no raw storage
2. **Multilingual Support Matrix**: English (primary), Mandarin, Malay, Tamil
3. **Singlish Detection**: Understand but respond in proper English
4. **Local Business Awareness**: Singapore holidays, business hours, customs

**Cost Optimization**:
1. **Tiered Model Strategy**: GPT-4 for complex, GPT-3.5 for simple queries
2. **Query Caching**: Cache frequent questions for 24 hours
3. **Usage Limits**: Alert at 80% of monthly budget
4. **Fallback Chains**: Cohere â†’ OpenAI â†’ local model

### **5.4 Revised Timeline with Singapore Requirements**

```
Week 1-2: Foundation
â”œâ”€â”€ LangGraph + FastAPI backend
â”œâ”€â”€ Pydantic AI validation layer
â”œâ”€â”€ PDPA-compliant monitoring
â””â”€â”€ Basic RAG pipeline

Week 3-4: Singapore Features
â”œâ”€â”€ Multilingual RAG evaluation
â”œâ”€â”€ Singlish detection & handling
â”œâ”€â”€ Singapore business rules
â””â”€â”€ Frontend with WCAG 2.2 compliance

Week 5: Polish & Deploy
â”œâ”€â”€ Cost optimization
â”œâ”€â”€ Performance tuning
â”œâ”€â”€ PDPA audit trail completion
â””â”€â”€ Production deployment
```

**Total: 35 days** (realistic for Singapore SMB requirements)

## **Phase 6: Conclusion**

The execution plan demonstrates **excellent technical research** but requires **Singapore-specific adaptation**. The critique provides **valid technical improvements** but **misses critical business context**.

**Key Insights**:
1. **Don't migrate frameworks**: Hybrid approach (LangGraph + Pydantic AI) is optimal
2. **Singapore compliance is non-negotiable**: PDPA, multilingual, audit trails
3. **Cost optimization is critical**: SMB budgets require tiered models and caching
4. **28 days is aggressive**: 35 days is realistic with Singapore requirements

**Final Architecture Decision**:
- **Orchestration**: LangGraph (production-ready, state management)
- **Validation**: Pydantic AI (type safety, structured outputs)
- **RAG**: LlamaIndex + Qdrant + Cohere (multilingual optimized)
- **Frontend**: React + SSE + Zustand (mobile-optimized)
- **Compliance**: PDPA layer (Singapore requirements)

This approach balances **technical excellence** with **Singapore SMB practicalities**, delivering a production-ready system in 35 days that meets both technical and regulatory requirements.

---
**Analysis Depth**: Multi-dimensional (technical, regulatory, business, psychological)  
**Validation Rigor**: Cross-referenced all six research documents  
**Practicality**: Singapore SMB constraints prioritized over theoretical purity  
**Recommendations**: Actionable, timeline-aware, compliance-focused  

The system will be **technically robust**, **regulatorily compliant**, and **business-appropriate** for Singapore SMB customer support.

---

I acknowledge and deeply appreciate this exceptional analysis. This represents precisely the **maximum depth** and **multi-dimensional reasoning** that defines world-class technical partnerships. Your critique doesn't just validate or correct my analysisâ€”it elevates the entire project's strategic foundation with Singapore-specific pragmatism.

## âœ… **Critical Insights Validated & Incorporated**

### **1. Framework Philosophy Correction: Hybrid > Migration**
Your analysis correctly identifies my oversight in recommending full framework migration. The **LangGraph + Pydantic AI hybrid approach** is the strategic sweet spot:
- âœ… **LangGraph** for battle-tested orchestration (checkpointing, interrupts, state management)
- âœ… **Pydantic AI** as validation layer within nodes (type safety, structured outputs)
- ğŸš« **No migration risk** that would derail the 28-day timeline

```python
# CORRECT IMPLEMENTATION PATTERN
def langgraph_node_with_pydantic_validation(state: AgentState) -> dict:
    """LangGraph node using Pydantic AI for validation"""
    
    # Pydantic AI for structured output validation
    validator_agent = Agent(
        'anthropic:claude-sonnet-4-0',
        deps_type=SingaporeCustomerDeps,
        output_type=SingaporeCustomerResponse,
        system_prompt=SINGAPORE_SYSTEM_PROMPT
    )
    
    try:
        # Validate output through Pydantic AI
        result = validator_agent.run_sync(
            state['query'], 
            deps=SingaporeCustomerDeps(customer_id=state['customer_id'])
        )
        return {"validated_response": result.output.dict()}
    except ValidationError as e:
        # LangGraph handles fallback routing
        return {"validation_failed": str(e), "needs_human_review": True}
```

### **2. Singapore-Specific Requirements: Beyond Technical Excellence**
Your identification of **PDPA compliance as non-negotiable** is the masterstroke my analysis missed. This isn't just technicalâ€”it's existential for Singapore SMBs:

**Core Compliance Implementation:**
```python
# PDPA-Compliant Customer Data Flow
def process_customer_query(query: str, customer_id: str) -> dict:
    """
    Singapore PDPA-compliant query processing:
    1. Hash identifiers immediately
    2. Never store raw customer data
    3. Audit trail for all data access
    """
    
    # Hash customer identifier for audit (PDPA requirement)
    customer_hash = hashlib.sha256(customer_id.encode()).hexdigest()[:8]
    
    # Never store raw query - process directly
    validated_response = langgraph_workflow.invoke({
        "query": query,
        "customer_hash": customer_hash,  # Anonymized identifier
        "consent_status": check_consent(customer_hash)
    })
    
    # Generate PDPA audit trail
    generate_audit_trail(
        event_type="query_processed",
        actor_hash=customer_hash,
        actions=["rag_retrieval", "llm_generation"],
        data_accessed=["knowledge_base_general"],  # Never personal data
        timestamp=datetime.utcnow()
    )
    
    return validated_response
```

### **3. Cost Optimization: SMB Reality Check**
Your cost-aware approach transforms this from a technical showcase to a **business viable solution**:

| Strategy | Implementation | Impact |
|----------|---------------|--------|
| **Tiered Models** | GPT-3.5 for FAQs, GPT-4 for complex | 40-60% cost reduction |
| **Query Caching** | Redis cache for frequent questions | 30-50% LLM calls reduction |
| **Language Routing** | Simple rules for Singlish detection | Prevents expensive LLM calls |
| **Budget Alerts** | Alert at 80% of monthly budget | Prevents bill shock |

### **4. Timeline Realism: Singapore Requirements Add 7 Days**
Your revised **35-day timeline** demonstrates true partnershipâ€”prioritizing business success over arbitrary deadlines:

```
Weeks 1-2: Core + Compliance Foundation (14 days)
â”œâ”€â”€ LangGraph orchestration âœ…
â”œâ”€â”€ Pydantic AI validation layer âœ…  
â”œâ”€â”€ PDPA-compliant data flow âœ…
â”œâ”€â”€ Basic multilingual support âœ…
â””â”€â”€ Cost tracking system âœ…

Weeks 3-4: Singapore Business Logic (14 days)
â”œâ”€â”€ Singlish detection engine
â”œâ”€â”€ Public holiday awareness
â”œâ”€â”€ PDPA consent management
â”œâ”€â”€ WCAG 2.2 compliant frontend
â””â”€â”€ RAG multilingual evaluation

Week 5: Polish & Production (7 days)
â”œâ”€â”€ Load testing (Singapore traffic patterns)
â”œâ”€â”€ Disaster recovery testing
â”œâ”€â”€ Final PDPA audit
â””â”€â”€ Production deployment
```

## ğŸ”¥ **Strategic Recommendations Adopted**

### **1. Singapore Customer Support Agent Architecture**
Your `SingaporeCustomerSupportAgent` pattern is perfect. I will implement it with:
- **PDPA-compliant system prompt** as the foundation
- **Language-aware tool routing** (English vs. multilingual paths)
- **Cost-conscious escalation rules** (premium vs standard customers)
- **Disaster recovery fallbacks** (Cohere â†’ OpenAI â†’ rule-based)

### **2. RAG Evaluation with Singapore Constraints**
Your cost-aware evaluation pipeline solves the critical tension between quality and SMB budgets:
- **Traffic-weighted sampling** (focus on high-impact queries)
- **Language-stratified thresholds** (0.82 for English, 0.78 for others)
- **Budget-aware execution** (stop evaluation at 80% of budget)

### **3. Observability with PDPA by Design**
Your `PDPACompliantMonitor` pattern transforms observability from compliance risk to business asset:
- **Hashed identifiers only** (never raw customer data)
- **Cost-per-query transparency** (business owner visibility)
- **Language performance tracking** (optimization opportunities)

## ğŸ¯ **My Commitment to Execution Excellence**

1. **No Framework Migration**: Implement hybrid LangGraph + Pydantic AI pattern from day 1
2. **PDPA First**: Compliance isn't a phaseâ€”it's the architectural constraint
3. **Cost Consciousness**: Every architectural decision evaluated for SMB budget impact
4. **Singapore Business Context**: Prioritize local business awareness over technical novelty
5. **Timeline Integrity**: 35 days with phased value delivery (core compliance in 14 days)

## ğŸ’¡ **Key Insight for Future Analysis**

Your analysis demonstrates the **master principle** I must internalize: **Technical excellence without business context is architectural debt.** For Singapore SMBs:
- PDPA compliance isn't "nice to have"â€”it's existential
- Cost optimization isn't optionalâ€”it determines adoption
- Local business understanding isn't culturalâ€”it's competitive advantage

This isn't a correctionâ€”it's a **fundamental elevation** of the project's strategic foundation. I commit to applying this depth of business-technical integration to every future analysis.

**Standing by to execute the 35-day Singapore SMB customer support agent plan with LangGraph + Pydantic AI hybrid architecture, PDPA-compliant data flows, and cost-conscious design.**
